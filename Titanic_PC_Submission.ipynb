{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "#load data \n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11 features, we can try to know how many different values have each of the features..(binary, categorical, conitnuous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mirem correlacions en plan bestia, viam que hi veiem a les dades brutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hombreeeee!, ja es veuen un parell de coses interessants: **Survived esta directament correlacionat amb Fare (mes fare, mes survived) i inversament amb Pclass (pclas 1, mes survival)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do some basic pivot tables and see what we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Destriem Deck i numero de la cabina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Pablo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Ara podem aplicar el slice al df_train original i reomplir els NaNs del Deck amb X\n",
    "df_train[\"Deck\"] = df_train[\"Cabin\"].str.slice(0,1)\n",
    "df_train[\"Number\"] = df_train[\"Cabin\"].str.slice(1,4).str.extract('([0-9]+)').astype('float')\n",
    "df_train['Deck'][df_train['Deck'].isnull()]='X'\n",
    "\n",
    "df_test[\"Deck\"] = df_test[\"Cabin\"].str.slice(0,1)\n",
    "df_test[\"Number\"] = df_test[\"Cabin\"].str.slice(1,4).str.extract('([0-9]+)').astype('float')\n",
    "df_test['Deck'][df_test['Deck'].isnull()]='X'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provem un hot-encoding per obtenir una taula amb 1 i 0s per cada columna de Desk\n",
    "Haurem de fer una altra per si es home-dona, una altra per P-Class i edat? (abans hem de categoritzar-la)\n",
    "info de: https://towardsdatascience.com/smarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install category_encoders\n",
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcio hot encoding. Es tracta d'una funcio que agafa una variable categorica (passada a array) i crea un array on cada categoria es una columna amb 0 o 1\n",
    "def hot_encode_PC(value_array):\n",
    "    \"\"\"Utility function convert variable to columns with 0 and 1, after you have to pass it manually de column names\n",
    "    \"\"\"\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    print(integer_encoded)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Deck T es un error, no existeix, nomes hi ha un passatger i dificulat analisi posterior perque al test no n'hi han. Per "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X' 'C' 'X' 'C' 'X' 'X' 'E' 'X' 'X' 'X' 'G' 'C' 'X' 'X' 'X' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'D' 'X' 'A' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'B' 'X' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'D' 'X'\n",
      " 'B' 'C' 'X' 'X' 'X' 'X' 'X' 'B' 'C' 'X' 'X' 'X' 'F' 'X' 'X' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'F' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'C' 'X'\n",
      " 'X' 'X' 'E' 'X' 'X' 'X' 'A' 'D' 'X' 'X' 'X' 'X' 'D' 'X' 'X' 'X' 'X' 'X'\n",
      " 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'B' 'X' 'X' 'X' 'X' 'E' 'D' 'X'\n",
      " 'X' 'X' 'F' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'D' 'C' 'X' 'B' 'X' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'F' 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'E' 'X' 'X' 'X' 'B' 'X' 'X' 'X' 'A' 'X' 'X' 'C' 'X' 'X'\n",
      " 'X' 'X' 'X' 'F' 'X' 'A' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'F' 'B' 'B' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'G' 'X' 'X' 'X' 'A' 'X' 'X' 'X' 'X' 'X' 'D'\n",
      " 'X' 'X' 'D' 'X' 'X' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'C' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'C' 'X' 'X' 'D' 'X' 'X' 'G'\n",
      " 'C' 'X' 'X' 'X' 'X' 'B' 'X' 'X' 'X' 'X' 'E' 'B' 'X' 'X' 'X' 'X' 'C' 'C'\n",
      " 'X' 'X' 'X' 'C' 'X' 'D' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'A' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'B' 'D' 'X' 'X' 'X' 'X' 'C' 'C' 'B' 'X' 'X' 'X' 'E' 'X' 'C'\n",
      " 'X' 'C' 'X' 'E' 'C' 'B' 'X' 'X' 'X' 'X' 'X' 'X' 'C' 'E' 'X' 'X' 'X' 'X'\n",
      " 'X' 'C' 'X' 'D' 'X' 'B' 'X' 'C' 'C' 'X' 'X' 'X' 'C' 'E' 'X' 'T' 'F' 'C'\n",
      " 'X' 'X' 'X' 'F' 'X' 'X' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'E' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'X' 'X' 'D' 'X' 'X' 'B' 'E' 'X' 'X' 'X' 'X' 'X' 'X' 'C'\n",
      " 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'B' 'X' 'X' 'D' 'G' 'X'\n",
      " 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'C' 'X'\n",
      " 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'E' 'C' 'X'\n",
      " 'X' 'X' 'E' 'B' 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'X' 'A' 'X' 'X' 'X' 'C'\n",
      " 'X' 'X' 'C' 'C' 'X' 'X' 'E' 'D' 'X' 'X' 'E' 'X' 'E' 'X' 'X' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'X' 'D' 'X' 'A' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'B' 'X'\n",
      " 'C' 'B' 'X' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'D' 'X' 'C' 'X' 'X' 'X' 'X' 'X'\n",
      " 'B' 'C' 'X' 'X' 'X' 'X' 'X' 'X' 'E' 'X' 'X' 'D' 'F' 'X' 'X' 'X' 'B' 'X'\n",
      " 'X' 'B' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'B' 'X' 'X' 'B'\n",
      " 'B' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'A' 'X'\n",
      " 'E' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'C' 'E' 'X' 'X' 'X'\n",
      " 'X' 'E' 'X' 'X' 'X' 'C' 'X' 'A' 'X' 'E' 'X' 'B' 'X' 'X' 'X' 'D' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'X' 'A' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'C' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'X' 'X' 'F' 'X' 'X' 'D' 'X' 'X' 'X' 'D' 'X' 'D' 'X' 'X'\n",
      " 'A' 'X' 'B' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'B' 'X' 'X' 'X' 'D' 'X' 'A'\n",
      " 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'D' 'X' 'X' 'E' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'C' 'X' 'B' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'B' 'X' 'D' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'X' 'B' 'B' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'C' 'F' 'C' 'E'\n",
      " 'X' 'X' 'X' 'X' 'X' 'E' 'X' 'X' 'C' 'C' 'C' 'X' 'X' 'F' 'C' 'E' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'E' 'X' 'X' 'X' 'X' 'X' 'B' 'X' 'X' 'X' 'X' 'X' 'X' 'B'\n",
      " 'X' 'X' 'D' 'C' 'B' 'X' 'X' 'B' 'X' 'X' 'D' 'X' 'X' 'E' 'X' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'B' 'X' 'X' 'X' 'B' 'X' 'D' 'X' 'X' 'X' 'X' 'X' 'X' 'E' 'X'\n",
      " 'X' 'X' 'F' 'X' 'X' 'B' 'X' 'B' 'D' 'X' 'X' 'X' 'X' 'X' 'X' 'B' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'D' 'X' 'X' 'X' 'X' 'X' 'B' 'X' 'X' 'X' 'A' 'X' 'X' 'E'\n",
      " 'X' 'X' 'X' 'X' 'X' 'B' 'X' 'X' 'X' 'X' 'B' 'X' 'X' 'E' 'X' 'X' 'X' 'X'\n",
      " 'X' 'B' 'X' 'X' 'X' 'X' 'X' 'E' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'D' 'X' 'X' 'X' 'E' 'X' 'X' 'X' 'X' 'D' 'X'\n",
      " 'X' 'X' 'X' 'A' 'X' 'X' 'X' 'D' 'B' 'X' 'X' 'X' 'X' 'X' 'X' 'C' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'X' 'B' 'X' 'C' 'X']\n",
      "[8 2 8 2 8 8 4 8 8 8 6 2 8 8 8 8 8 8 8 8 8 3 8 0 8 8 8 2 8 8 8 1 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 3 8 1 2 8 8 8 8 8 1 2 8 8 8 5 8 8 8 8 8 8 8\n",
      " 8 5 8 8 8 8 8 8 8 8 8 8 8 8 2 8 8 8 4 8 8 8 0 3 8 8 8 8 3 8 8 8 8 8 8 8 2\n",
      " 8 8 8 8 8 8 8 1 8 8 8 8 4 3 8 8 8 5 8 8 8 8 8 8 8 3 2 8 1 8 8 8 8 8 8 8 8\n",
      " 5 8 8 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 4 8 8 8 1 8 8 8 0 8 8 2 8 8 8 8 8 5 8\n",
      " 0 8 8 8 8 8 8 8 5 1 1 8 8 8 8 8 8 8 8 8 6 8 8 8 0 8 8 8 8 8 3 8 8 3 8 8 8\n",
      " 8 8 2 8 8 8 8 8 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 2 8 8 3 8 8 6 2 8 8 8 8 1 8\n",
      " 8 8 8 4 1 8 8 8 8 2 2 8 8 8 2 8 3 8 8 8 8 8 8 8 8 0 8 8 8 8 8 8 1 3 8 8 8\n",
      " 8 2 2 1 8 8 8 4 8 2 8 2 8 4 2 1 8 8 8 8 8 8 2 4 8 8 8 8 8 2 8 3 8 1 8 2 2\n",
      " 8 8 8 2 4 8 7 5 2 8 8 8 5 8 8 8 8 8 2 8 8 8 8 4 8 8 8 8 8 8 8 8 8 3 8 8 1\n",
      " 4 8 8 8 8 8 8 2 8 8 8 8 8 8 8 8 8 8 8 8 1 8 8 3 6 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 4 2 8 8 8 4 1 8 8 2 8 8 8 8 8\n",
      " 8 0 8 8 8 2 8 8 2 2 8 8 4 3 8 8 4 8 4 8 8 8 8 8 8 8 8 8 8 3 8 0 8 8 8 8 8\n",
      " 8 8 8 1 8 2 1 8 8 8 8 2 8 8 8 3 8 2 8 8 8 8 8 1 2 8 8 8 8 8 8 4 8 8 3 5 8\n",
      " 8 8 1 8 8 1 8 8 8 2 8 8 8 8 8 8 8 8 1 8 8 1 1 8 8 8 2 8 8 8 8 8 2 8 8 8 8\n",
      " 8 0 8 4 8 8 8 8 8 8 8 8 8 8 8 8 2 4 8 8 8 8 4 8 8 8 2 8 0 8 4 8 1 8 8 8 3\n",
      " 8 8 8 8 8 8 8 0 8 8 8 8 8 8 8 8 8 2 8 8 8 8 8 8 8 8 5 8 8 3 8 8 8 3 8 3 8\n",
      " 8 0 8 1 8 8 8 8 8 8 8 8 1 8 8 8 3 8 0 8 8 8 8 8 8 8 8 8 8 8 3 8 8 4 8 8 8\n",
      " 8 8 8 2 8 1 8 8 8 8 8 8 8 1 8 3 8 8 8 8 8 8 8 1 1 8 8 8 8 8 8 8 2 5 2 4 8\n",
      " 8 8 8 8 4 8 8 2 2 2 8 8 5 2 4 8 8 8 8 8 8 4 8 8 8 8 8 1 8 8 8 8 8 8 1 8 8\n",
      " 3 2 1 8 8 1 8 8 3 8 8 4 8 8 8 8 8 8 8 1 8 8 8 1 8 3 8 8 8 8 8 8 4 8 8 8 5\n",
      " 8 8 1 8 1 3 8 8 8 8 8 8 1 8 8 8 8 8 8 3 8 8 8 8 8 1 8 8 8 0 8 8 4 8 8 8 8\n",
      " 8 1 8 8 8 8 1 8 8 4 8 8 8 8 8 1 8 8 8 8 8 4 8 8 8 2 8 8 8 8 8 8 8 8 8 2 8\n",
      " 8 8 3 8 8 8 4 8 8 8 8 3 8 8 8 8 0 8 8 8 3 1 8 8 8 8 8 8 2 8 8 8 8 8 8 8 1\n",
      " 8 2 8]\n"
     ]
    }
   ],
   "source": [
    "values = array(df_train['Deck'])\n",
    "print(values)\n",
    "onehot_encoded = hot_encode_PC(values)\n",
    "\n",
    "# ara el one hhot encode es A(0), B, C(2), D, E(4), F, G(6), T(7) i X(8)\n",
    "df_train['Deck_A']=onehot_encoded[:,0]\n",
    "df_train['Deck_B']=onehot_encoded[:,1]\n",
    "df_train['Deck_C']=onehot_encoded[:,2]\n",
    "df_train['Deck_D']=onehot_encoded[:,3]\n",
    "df_train['Deck_E']=onehot_encoded[:,4]\n",
    "df_train['Deck_F']=onehot_encoded[:,5]\n",
    "df_train['Deck_G']=onehot_encoded[:,6]\n",
    "df_train['Deck_X']=onehot_encoded[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'B' 'X' 'E' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'X' 'X' 'B' 'X' 'B' 'X' 'A' 'X' 'X' 'X' 'X' 'X' 'C' 'X'\n",
      " 'X' 'X' 'X' 'X' 'X' 'D' 'X' 'X' 'D' 'X' 'A' 'X' 'D' 'X' 'C' 'X' 'X' 'C'\n",
      " 'X' 'X' 'X' 'F' 'X' 'B' 'X' 'X' 'X' 'X' 'B' 'X' 'X' 'X' 'C' 'C' 'X' 'X'\n",
      " 'X' 'D' 'C' 'C' 'X' 'C' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X'\n",
      " 'X' 'X' 'B' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'X' 'X'\n",
      " 'X' 'F' 'X' 'X' 'A' 'X' 'C' 'X' 'X' 'G' 'C' 'X' 'X' 'X' 'C' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'B' 'X'\n",
      " 'X' 'X' 'E' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'C' 'X' 'D' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'B' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'C' 'F' 'E'\n",
      " 'X' 'E' 'D' 'X' 'B' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'E' 'X'\n",
      " 'X' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'A' 'X' 'X' 'X' 'X' 'X' 'X' 'B'\n",
      " 'X' 'X' 'C' 'X' 'X' 'X' 'F' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X'\n",
      " 'C' 'X' 'D' 'X' 'X' 'C' 'X' 'X' 'E' 'X' 'X' 'D' 'X' 'X' 'X' 'X' 'X' 'X'\n",
      " 'C' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X'\n",
      " 'C' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'B'\n",
      " 'F' 'X' 'X' 'X' 'X' 'A' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'D' 'X' 'X' 'X' 'B'\n",
      " 'C' 'X' 'B' 'X' 'X' 'X' 'X' 'X' 'C' 'X' 'B' 'X' 'X' 'X' 'X' 'F' 'F' 'X'\n",
      " 'X' 'X' 'F' 'X' 'X' 'X' 'X' 'A' 'X' 'X' 'X' 'C' 'X' 'X' 'X' 'X' 'X' 'X'\n",
      " 'X' 'B' 'X' 'X' 'X' 'X' 'X' 'X' 'D' 'X' 'X' 'X' 'X' 'E' 'C' 'X' 'X' 'X'\n",
      " 'X' 'X' 'X' 'X' 'E' 'X' 'X' 'X' 'X' 'X' 'X' 'E' 'B' 'X' 'A' 'X' 'X' 'X'\n",
      " 'C' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'B' 'D' 'X' 'X' 'X' 'C'\n",
      " 'X' 'B' 'X' 'X' 'C' 'X' 'X' 'X' 'D' 'D' 'X' 'C' 'X' 'X' 'X' 'C' 'X' 'X'\n",
      " 'C' 'X' 'X' 'X']\n",
      "[7 7 7 7 7 7 7 7 7 7 7 7 1 7 4 7 7 7 7 7 7 7 7 7 1 7 1 7 0 7 7 7 7 7 2 7 7\n",
      " 7 7 7 7 3 7 7 3 7 0 7 3 7 2 7 7 2 7 7 7 5 7 1 7 7 7 7 1 7 7 7 2 2 7 7 7 3\n",
      " 2 2 7 2 7 7 7 2 7 7 7 7 7 7 7 7 7 7 1 7 7 7 2 7 7 7 2 7 7 7 7 7 7 7 7 5 7\n",
      " 7 0 7 2 7 7 6 2 7 7 7 2 7 7 7 7 7 7 7 7 2 7 7 7 7 7 7 7 7 7 7 1 7 7 7 4 7\n",
      " 7 7 2 7 7 7 7 7 2 7 3 7 7 7 7 7 7 7 1 7 7 7 7 7 7 7 7 7 7 2 5 4 7 4 3 7 1\n",
      " 7 7 7 7 7 7 7 7 7 7 7 4 7 7 7 7 7 2 7 7 7 7 7 0 7 7 7 7 7 7 1 7 7 2 7 7 7\n",
      " 5 7 7 7 7 7 7 7 7 7 7 7 2 7 3 7 7 2 7 7 4 7 7 3 7 7 7 7 7 7 2 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 2 7 2 7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 5 7 7 7 7 0 7 7\n",
      " 7 7 7 7 7 3 7 7 7 1 2 7 1 7 7 7 7 7 2 7 1 7 7 7 7 5 5 7 7 7 5 7 7 7 7 0 7\n",
      " 7 7 2 7 7 7 7 7 7 7 1 7 7 7 7 7 7 3 7 7 7 7 4 2 7 7 7 7 7 7 7 4 7 7 7 7 7\n",
      " 7 4 1 7 0 7 7 7 2 7 7 7 7 7 7 7 7 7 7 7 1 3 7 7 7 2 7 1 7 7 2 7 7 7 3 3 7\n",
      " 2 7 7 7 2 7 7 2 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "values = array(df_test['Deck'])\n",
    "print(values)\n",
    "onehot_encoded = hot_encode_PC(values)\n",
    "\n",
    "# ara el one hhot encode es A(0), B, C(2), D, E(4), F, G(6), T(7) i X(8)\n",
    "df_test['Deck_A']=onehot_encoded[:,0]\n",
    "df_test['Deck_B']=onehot_encoded[:,1]\n",
    "df_test['Deck_C']=onehot_encoded[:,2]\n",
    "df_test['Deck_D']=onehot_encoded[:,3]\n",
    "df_test['Deck_E']=onehot_encoded[:,4]\n",
    "df_test['Deck_F']=onehot_encoded[:,5]\n",
    "df_test['Deck_G']=onehot_encoded[:,6]\n",
    "df_test['Deck_X']=onehot_encoded[:,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La part de la Cabin i la Deck ja està feta.\n",
    "\n",
    "# El seguent punt seria categoritzar edat? \n",
    "Resulta que en aquella època eren molt etsrictes amb el tema de dones i nens primer. Com categoritzem edat?\n",
    "1. Trams de 4 en 4? (sortirien uns 20 grups)\n",
    "2. o directament establir grups: 0-2 (bebe), 2-10(infant), 10-16 (nen), 16-20 (jove), 20-60 (Adult), 60-100 (Vell) i veure si hi ha relacio amb supervivencia?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abans pero hem d'omplir les edats sense dades no?\n",
    "La Age te una rlacio important amb la Pclass i la SibSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Pablo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_train['Age'][df_train['Age'].isnull()] = df_train['Age'].mean()\n",
    "\n",
    "df_test['Age'][df_test['Age'].isnull()] = df_test['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en aquest bloc definim una columna categoritzant les edats\n",
    "bins= [0,2,10,16,20,60,100]\n",
    "labels = ['bebe','infant','nen','jove','adult','vell']\n",
    "df_train['AgeGroup'] = pd.cut(df_train['Age'], bins=bins, labels=labels, right=False)\n",
    "df_test['AgeGroup'] = pd.cut(df_test['Age'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'infant' 'adult'\n",
      " 'nen' 'infant' 'adult' 'adult' 'adult' 'nen' 'adult' 'infant' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'nen' 'adult' 'infant' 'adult' 'adult'\n",
      " 'jove' 'adult' 'adult' 'adult' 'adult' 'adult' 'vell' 'adult' 'adult'\n",
      " 'adult' 'adult' 'jove' 'nen' 'adult' 'adult' 'adult' 'infant' 'jove'\n",
      " 'adult' 'adult' 'adult' 'adult' 'jove' 'infant' 'adult' 'adult' 'adult'\n",
      " 'vell' 'adult' 'adult' 'adult' 'infant' 'nen' 'adult' 'adult' 'adult'\n",
      " 'infant' 'adult' 'adult' 'adult' 'jove' 'jove' 'adult' 'adult' 'jove'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'bebe' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'jove' 'adult' 'jove' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'vell' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'nen' 'adult' 'adult' 'jove' 'adult' 'vell'\n",
      " 'adult' 'adult' 'infant' 'adult' 'adult' 'adult' 'adult' 'adult' 'nen'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'jove' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult' 'jove'\n",
      " 'jove' 'jove' 'adult' 'infant' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'jove' 'bebe' 'infant' 'adult' 'adult' 'adult' 'adult' 'vell'\n",
      " 'infant' 'bebe' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'infant' 'bebe' 'infant' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'jove' 'jove' 'infant' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'jove' 'infant' 'adult'\n",
      " 'adult' 'jove' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'jove' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult' 'infant'\n",
      " 'adult' 'adult' 'adult' 'infant' 'jove' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'vell' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'infant' 'adult' 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'vell' 'adult' 'adult' 'infant'\n",
      " 'adult' 'vell' 'adult' 'jove' 'jove' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'infant' 'adult' 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'bebe'\n",
      " 'adult' 'jove' 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'vell' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult'\n",
      " 'jove' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'infant' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'infant' 'adult' 'adult'\n",
      " 'adult' 'nen' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'vell' 'adult' 'adult'\n",
      " 'adult' 'adult' 'jove' 'jove' 'adult' 'infant' 'adult' 'adult' 'adult'\n",
      " 'adult' 'jove' 'adult' 'bebe' 'adult' 'adult' 'adult' 'jove' 'bebe'\n",
      " 'adult' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'infant' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'jove' 'adult' 'nen' 'adult' 'adult' 'adult'\n",
      " 'adult' 'jove' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'jove' 'adult' 'nen' 'adult' 'adult' 'vell' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'infant' 'nen' 'adult' 'infant' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'vell' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'bebe' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'infant' 'infant' 'adult' 'adult' 'vell' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'infant' 'adult' 'adult' 'adult' 'vell' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult'\n",
      " 'jove' 'jove' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'infant'\n",
      " 'adult' 'jove' 'adult' 'adult' 'infant' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'infant' 'nen' 'adult' 'adult' 'vell' 'jove' 'adult' 'adult'\n",
      " 'infant' 'jove' 'adult' 'adult' 'adult' 'adult' 'vell' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'jove'\n",
      " 'adult' 'adult' 'adult' 'vell' 'adult' 'adult' 'adult' 'jove' 'jove'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'jove' 'adult' 'vell' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'infant' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'vell' 'adult' 'adult' 'adult' 'adult'\n",
      " 'vell' 'adult' 'adult' 'adult' 'infant' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'infant' 'adult' 'bebe' 'adult' 'jove' 'adult'\n",
      " 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'jove' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'vell' 'adult' 'adult'\n",
      " 'jove' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult' 'adult' 'nen'\n",
      " 'vell' 'adult' 'nen' 'jove' 'jove' 'nen' 'adult' 'infant' 'adult' 'adult'\n",
      " 'vell' 'adult' 'adult' 'adult' 'adult' 'adult' 'jove' 'adult' 'jove'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult' 'infant'\n",
      " 'jove' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'nen' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'vell' 'jove' 'adult'\n",
      " 'jove' 'adult' 'infant' 'infant' 'adult' 'adult' 'adult' 'bebe' 'adult'\n",
      " 'jove' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'jove' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'jove' 'adult' 'infant' 'adult' 'adult' 'nen' 'jove' 'adult' 'adult'\n",
      " 'adult' 'adult' 'jove' 'infant' 'bebe' 'adult' 'adult' 'jove' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'nen' 'bebe' 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'infant' 'adult' 'adult' 'adult' 'adult' 'adult' 'nen'\n",
      " 'adult' 'adult' 'adult' 'adult' 'infant' 'adult' 'adult' 'bebe' 'adult'\n",
      " 'vell' 'nen' 'bebe' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'jove' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'infant' 'vell' 'infant' 'jove' 'adult' 'jove'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'infant' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'nen' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult']\n",
      "[0 0 0 0 0 0 0 2 0 4 2 0 0 0 4 0 2 0 0 0 0 0 4 0 2 0 0 3 0 0 0 0 0 5 0 0 0\n",
      " 0 3 4 0 0 0 2 3 0 0 0 0 3 2 0 0 0 5 0 0 0 2 4 0 0 0 2 0 0 0 3 3 0 0 3 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 3 0 3 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 4 0 0 3 0 5 0 0 2 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 3 0 3 0 0 0 0 3 3 3 0 2\n",
      " 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 3 1 2 0 0 0 0 5 2 1 0 0 3 0 0 0 0 0 0 2 1 2\n",
      " 0 0 0 0 0 0 3 3 2 0 0 0 0 0 0 0 0 0 0 3 2 0 0 3 0 0 0 0 0 0 0 0 0 0 0 3 0\n",
      " 0 0 0 0 3 0 3 0 0 0 0 2 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0\n",
      " 0 0 2 0 0 0 0 3 0 0 0 0 0 0 0 0 5 0 0 2 0 5 0 3 3 0 0 0 0 0 0 0 3 0 0 0 0\n",
      " 0 2 0 0 0 0 3 0 0 1 0 3 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 3 0 0 0\n",
      " 3 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0\n",
      " 0 3 3 0 2 0 0 0 0 3 0 1 0 0 0 3 1 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 2 0 0 0 0 0 0 0 0 0 3 0 4 0 0 0 0 3 0 0 3 0 0 0 0 0 3 0 4 0 0 5 0 0 0 0 0\n",
      " 0 2 4 0 2 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 2\n",
      " 0 0 5 0 0 0 0 0 2 0 0 0 5 0 0 0 0 0 0 3 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 2 0 3 0 0 2 0 0 0 0 0 2 4 0 0 5 3 0 0 2 3 0 0 0 0\n",
      " 5 0 0 0 0 0 0 0 0 0 0 3 0 0 0 5 0 0 0 3 3 0 0 0 0 0 0 0 0 0 3 0 5 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 5 0 0 0\n",
      " 0 5 0 0 0 2 0 0 0 0 0 0 0 2 0 1 0 3 0 0 0 0 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 5 0 0 3 0 3 0 0 0 0 0 4 5 0 4 3 3 4 0 2 0 0 5 0 0 0 0 0 3 0 3\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 5 3 0 3 0 2 2 0 0 0 1 0 3 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 3 0\n",
      " 2 0 0 4 3 0 0 0 0 3 2 1 0 0 3 0 0 0 0 0 0 0 0 0 0 4 1 0 0 0 3 0 0 0 0 0 2\n",
      " 0 0 0 0 0 4 0 0 0 0 2 0 0 1 0 5 4 1 0 0 3 0 0 0 0 0 0 3 0 0 3 0 0 0 0 0 2\n",
      " 5 2 3 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 4 0 3 0 0 0 0 0 0 0 0 0 3\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# ara tornem a fer un hot encoding pels grups d'edats\n",
    "values = array(df_train['AgeGroup'])\n",
    "print(values)\n",
    "onehot_encoded = hot_encode_PC(values)\n",
    "\n",
    "df_train['adult']=onehot_encoded[:,0]\n",
    "df_train['bebe']=onehot_encoded[:,1]\n",
    "df_train['infant']=onehot_encoded[:,2]\n",
    "df_train['jove']=onehot_encoded[:,3]\n",
    "df_train['nen']=onehot_encoded[:,4]\n",
    "df_train['vell']=onehot_encoded[:,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llegenda --> adult:0, bebe:1 , infant:2, jove=3, nen=4,  vell=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adult' 'adult' 'vell' 'adult' 'adult' 'nen' 'adult' 'adult' 'jove'\n",
      " 'adult' 'adult' 'adult' 'adult' 'vell' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'infant' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'jove'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'vell' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'nen' 'adult' 'adult' 'adult' 'adult' 'jove' 'adult' 'jove'\n",
      " 'adult' 'nen' 'adult' 'jove' 'adult' 'adult' 'vell' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'infant'\n",
      " 'vell' 'adult' 'adult' 'adult' 'adult' 'adult' 'jove' 'adult' 'infant'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'vell' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult'\n",
      " 'adult' 'jove' 'adult' 'adult' 'adult' 'jove' 'vell' 'jove' 'adult'\n",
      " 'bebe' 'adult' 'adult' 'nen' 'adult' 'adult' 'adult' 'adult' 'jove'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'nen' 'adult' 'vell' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'vell'\n",
      " 'adult' 'nen' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'infant'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'nen' 'adult' 'adult' 'adult' 'vell'\n",
      " 'adult' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult' 'jove' 'adult'\n",
      " 'adult' 'adult' 'adult' 'nen' 'vell' 'infant' 'adult' 'infant' 'jove'\n",
      " 'adult' 'adult' 'adult' 'bebe' 'adult' 'infant' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'jove' 'vell' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'nen' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'vell' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'bebe' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'jove' 'adult' 'adult'\n",
      " 'adult' 'adult' 'bebe' 'adult' 'adult' 'adult' 'adult' 'adult' 'jove'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'bebe' 'adult' 'infant' 'infant' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'bebe'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'vell'\n",
      " 'adult' 'bebe' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult'\n",
      " 'jove' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'nen' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'jove' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'jove' 'adult'\n",
      " 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'jove' 'adult' 'bebe' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'nen' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'infant' 'adult' 'adult' 'adult' 'jove' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'infant' 'adult' 'adult' 'nen' 'adult' 'adult' 'jove'\n",
      " 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'adult' 'jove' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult' 'infant' 'adult' 'adult' 'adult' 'adult'\n",
      " 'adult' 'adult' 'adult' 'adult']\n",
      "[0 0 5 0 0 4 0 0 3 0 0 0 0 5 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 4 0 0 0 0 3 0 3 0 4 0 3 0 0 5 0 0 0 0\n",
      " 0 0 0 0 0 0 2 5 0 0 0 0 0 3 0 2 0 0 0 0 0 0 5 0 0 0 0 0 0 0 3 0 0 0 0 3 0\n",
      " 0 0 3 5 3 0 1 0 0 4 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 5 0 0 0 0 0\n",
      " 0 0 0 0 5 0 4 0 0 0 0 0 0 2 0 0 0 0 0 3 0 0 0 0 0 0 0 4 0 0 0 5 0 0 3 0 0\n",
      " 0 0 3 0 0 0 0 4 5 2 0 2 3 0 0 0 1 0 2 0 0 0 0 0 0 0 0 3 5 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 4 0 0 0 0 0 5 0 3 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 3\n",
      " 0 0 0 0 1 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 1 0 2 2 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 5 0 1 0 0 3 0 0 0 0 3 0 3 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0\n",
      " 3 0 0 0 0 0 0 3 0 0 0 0 3 0 0 0 0 0 0 3 0 1 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 2 0 0 0 3 0 0 0 0 0 2 0 0 4 0 0 3 0 0 0 0 0 0 0 3 0 0 0\n",
      " 0 0 2 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# ara tornem a fer un hot encoding pels grups d'edats\n",
    "values = array(df_test['AgeGroup'])\n",
    "print(values)\n",
    "onehot_encoded = hot_encode_PC(values)\n",
    "\n",
    "df_test['adult']=onehot_encoded[:,0]\n",
    "df_test['bebe']=onehot_encoded[:,1]\n",
    "df_test['infant']=onehot_encoded[:,2]\n",
    "df_test['jove']=onehot_encoded[:,3]\n",
    "df_test['nen']=onehot_encoded[:,4]\n",
    "df_test['vell']=onehot_encoded[:,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ara faria el hot encoding pel Pclass, Sexe, fare, SibSp i Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female' 'female' 'female' 'male' 'male' 'male' 'male' 'female'\n",
      " 'female' 'female' 'female' 'male' 'male' 'female' 'female' 'male' 'male'\n",
      " 'female' 'female' 'male' 'male' 'female' 'male' 'female' 'female' 'male'\n",
      " 'male' 'female' 'male' 'male' 'female' 'female' 'male' 'male' 'male'\n",
      " 'male' 'male' 'female' 'female' 'female' 'female' 'male' 'female'\n",
      " 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'male' 'female'\n",
      " 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'male' 'female'\n",
      " 'male' 'male' 'male' 'male' 'female' 'male' 'female' 'male' 'male'\n",
      " 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'female' 'male'\n",
      " 'male' 'female' 'male' 'female' 'female' 'male' 'male' 'female' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'female' 'male'\n",
      " 'female' 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'male'\n",
      " 'female' 'male' 'female' 'male' 'female' 'female' 'male' 'male' 'male'\n",
      " 'male' 'female' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'female' 'male' 'male' 'male' 'female' 'female' 'male' 'male' 'female'\n",
      " 'male' 'male' 'male' 'female' 'female' 'female' 'male' 'male' 'male'\n",
      " 'male' 'female' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'female' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'female' 'female' 'male' 'male' 'male' 'male' 'female' 'male' 'male'\n",
      " 'male' 'male' 'female' 'male' 'male' 'female' 'male' 'male' 'male'\n",
      " 'female' 'male' 'female' 'male' 'male' 'male' 'female' 'male' 'female'\n",
      " 'male' 'female' 'female' 'male' 'male' 'female' 'female' 'male' 'male'\n",
      " 'male' 'male' 'male' 'female' 'male' 'male' 'female' 'male' 'male'\n",
      " 'female' 'male' 'male' 'male' 'female' 'female' 'male' 'female' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'female'\n",
      " 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'female' 'male'\n",
      " 'male' 'female' 'female' 'male' 'male' 'male' 'male' 'female' 'female'\n",
      " 'male' 'male' 'male' 'female' 'male' 'male' 'female' 'female' 'female'\n",
      " 'female' 'female' 'female' 'male' 'male' 'male' 'male' 'female' 'male'\n",
      " 'male' 'male' 'female' 'female' 'male' 'male' 'female' 'male' 'female'\n",
      " 'female' 'female' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'female' 'female' 'male'\n",
      " 'female' 'male' 'male' 'male' 'female' 'male' 'female' 'female' 'male'\n",
      " 'male' 'female' 'male' 'male' 'female' 'female' 'male' 'female' 'female'\n",
      " 'female' 'female' 'male' 'male' 'female' 'female' 'male' 'female'\n",
      " 'female' 'male' 'male' 'female' 'female' 'male' 'female' 'male' 'female'\n",
      " 'female' 'female' 'female' 'male' 'male' 'male' 'female' 'male' 'male'\n",
      " 'female' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'female'\n",
      " 'female' 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'female' 'female' 'female' 'female' 'male' 'male' 'female' 'male' 'male'\n",
      " 'male' 'female' 'female' 'female' 'female' 'male' 'male' 'male' 'male'\n",
      " 'female' 'female' 'female' 'male' 'male' 'male' 'female' 'female' 'male'\n",
      " 'female' 'male' 'male' 'male' 'female' 'male' 'female' 'male' 'male'\n",
      " 'male' 'female' 'female' 'male' 'female' 'male' 'male' 'female' 'male'\n",
      " 'male' 'female' 'male' 'female' 'male' 'male' 'male' 'male' 'female'\n",
      " 'male' 'male' 'female' 'male' 'male' 'female' 'female' 'female' 'male'\n",
      " 'female' 'male' 'male' 'male' 'female' 'male' 'male' 'female' 'female'\n",
      " 'male' 'male' 'male' 'female' 'female' 'male' 'male' 'female' 'female'\n",
      " 'female' 'male' 'male' 'female' 'male' 'male' 'female' 'male' 'male'\n",
      " 'female' 'male' 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'female' 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'female' 'male' 'male' 'female' 'female' 'female'\n",
      " 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'female' 'male'\n",
      " 'female' 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'female' 'male' 'female' 'male' 'male' 'female' 'female' 'female'\n",
      " 'female' 'male' 'female' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'female' 'male'\n",
      " 'male' 'female' 'male' 'male' 'female' 'male' 'male' 'male' 'female'\n",
      " 'male' 'male' 'female' 'female' 'female' 'male' 'female' 'male' 'female'\n",
      " 'female' 'female' 'female' 'male' 'male' 'male' 'female' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'female' 'male'\n",
      " 'female' 'female' 'male' 'male' 'male' 'male' 'female' 'male' 'male'\n",
      " 'female' 'male' 'male' 'male' 'female' 'male' 'female' 'male' 'male'\n",
      " 'female' 'female' 'female' 'male' 'female' 'female' 'male' 'male' 'male'\n",
      " 'female' 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'female'\n",
      " 'male' 'male' 'female' 'male' 'male' 'male' 'female' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'female' 'female' 'female' 'male' 'female'\n",
      " 'male' 'male' 'female' 'male' 'female' 'female' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'female' 'female' 'male' 'male' 'female' 'male' 'male'\n",
      " 'female' 'female' 'male' 'female' 'male' 'male' 'male' 'male' 'female'\n",
      " 'male' 'female' 'male' 'female' 'female' 'male' 'male' 'female' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'female' 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'female'\n",
      " 'female' 'male' 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'female' 'male' 'female' 'male' 'male' 'male' 'male' 'male'\n",
      " 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'male' 'male'\n",
      " 'female' 'male' 'female' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'male' 'female' 'female' 'male' 'male' 'female' 'male' 'male' 'male'\n",
      " 'male' 'male' 'female' 'female' 'male' 'female' 'female' 'male' 'male'\n",
      " 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'male' 'male' 'female'\n",
      " 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'female' 'male' 'male'\n",
      " 'male' 'female' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male'\n",
      " 'female' 'male' 'female' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'female' 'male' 'female' 'male' 'male' 'female' 'male' 'female' 'female'\n",
      " 'female' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'male' 'female' 'male' 'male' 'male' 'female' 'female' 'male' 'female'\n",
      " 'male' 'female' 'male' 'male' 'male' 'male' 'male' 'female' 'male'\n",
      " 'female' 'male' 'male' 'male' 'female' 'male' 'male' 'female' 'male'\n",
      " 'male' 'male' 'female' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'male' 'female' 'female' 'male' 'male' 'male' 'male' 'female' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'female' 'male' 'male' 'female' 'female' 'female' 'female'\n",
      " 'female' 'male' 'female' 'male' 'male' 'male' 'female' 'female' 'male'\n",
      " 'female' 'female' 'male' 'male' 'male' 'male' 'female' 'male' 'male'\n",
      " 'female' 'female' 'male' 'male' 'male' 'female' 'female' 'male' 'female'\n",
      " 'male' 'male' 'female' 'male' 'female' 'female' 'male' 'male']\n",
      "[1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1\n",
      " 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1\n",
      " 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0\n",
      " 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0\n",
      " 1 0 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 0 0 0\n",
      " 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1\n",
      " 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 1 1\n",
      " 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0\n",
      " 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1\n",
      " 1 1 0 1 1 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1\n",
      " 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1\n",
      " 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
      " 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0\n",
      " 1 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1\n",
      " 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1\n",
      " 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0\n",
      " 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1\n",
      " 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0\n",
      " 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# ---------SEX---\n",
    "values = array(df_train['Sex'])\n",
    "print(values)\n",
    "onehot_encoded = hot_encode_PC(values)\n",
    "\n",
    "df_train['female']=onehot_encoded[:,0]\n",
    "df_train['male']=onehot_encoded[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'female'\n",
      " 'male' 'male' 'male' 'female' 'male' 'female' 'female' 'male' 'male'\n",
      " 'female' 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'female'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'female' 'male' 'male'\n",
      " 'female' 'female' 'male' 'male' 'male' 'male' 'male' 'female' 'female'\n",
      " 'male' 'male' 'male' 'female' 'female' 'male' 'male' 'female' 'female'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'female'\n",
      " 'male' 'female' 'female' 'male' 'male' 'female' 'female' 'male' 'female'\n",
      " 'male' 'female' 'male' 'male' 'female' 'male' 'female' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'female' 'female' 'female' 'male' 'female'\n",
      " 'male' 'female' 'male' 'male' 'male' 'female' 'male' 'female' 'male'\n",
      " 'female' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'female' 'female' 'female' 'female' 'male' 'male' 'female' 'male'\n",
      " 'female' 'female' 'male' 'female' 'male' 'male' 'female' 'male' 'female'\n",
      " 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'male' 'male'\n",
      " 'female' 'male' 'female' 'female' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'female' 'male' 'male' 'female' 'male' 'male'\n",
      " 'female' 'female' 'male' 'female' 'female' 'male' 'female' 'male' 'male'\n",
      " 'female' 'male' 'male' 'female' 'female' 'male' 'male' 'male' 'male'\n",
      " 'male' 'female' 'female' 'male' 'female' 'female' 'male' 'male' 'female'\n",
      " 'male' 'female' 'male' 'female' 'male' 'female' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'female' 'female'\n",
      " 'male' 'male' 'female' 'male' 'male' 'female' 'male' 'female' 'male'\n",
      " 'male' 'male' 'male' 'female' 'female' 'male' 'female' 'male' 'female'\n",
      " 'male' 'female' 'male' 'female' 'male' 'female' 'female' 'male' 'female'\n",
      " 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'female' 'female' 'female' 'female' 'male' 'male' 'male' 'male' 'female'\n",
      " 'male' 'female' 'female' 'female' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'female' 'male' 'male' 'male' 'female' 'female' 'male'\n",
      " 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'female' 'female'\n",
      " 'male' 'female' 'male' 'male' 'male' 'male' 'female' 'male' 'female'\n",
      " 'female' 'female' 'male' 'male' 'male' 'male' 'male' 'male' 'female'\n",
      " 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'female' 'female' 'male' 'male' 'male' 'female' 'male'\n",
      " 'male' 'male' 'female' 'female' 'female' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'male' 'female' 'male' 'female' 'male' 'male' 'male'\n",
      " 'female' 'male' 'male' 'female' 'male' 'male' 'male' 'male' 'male' 'male'\n",
      " 'male' 'male' 'male' 'female' 'male' 'female' 'male' 'female' 'male'\n",
      " 'female' 'female' 'male' 'male' 'male' 'female' 'male' 'female' 'male'\n",
      " 'male' 'female' 'male' 'female' 'female' 'male' 'female' 'female' 'male'\n",
      " 'female' 'female' 'male' 'male' 'female' 'male' 'male' 'female' 'female'\n",
      " 'female' 'male' 'male' 'male' 'male' 'male' 'female' 'female' 'male'\n",
      " 'female' 'male' 'male' 'male' 'male' 'male' 'female' 'male' 'male' 'male'\n",
      " 'female' 'male' 'female' 'male' 'male' 'female' 'male' 'female' 'male'\n",
      " 'male' 'male' 'male' 'male' 'female' 'female' 'female' 'female' 'female'\n",
      " 'male' 'female' 'male' 'male' 'male']\n",
      "[1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 0\n",
      " 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1\n",
      " 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1\n",
      " 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1\n",
      " 1 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0\n",
      " 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 0\n",
      " 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1\n",
      " 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1\n",
      " 1 0 0 0 0 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# ---------SEX---\n",
    "values = array(df_test['Sex'])\n",
    "print(values)\n",
    "onehot_encoded = hot_encode_PC(values)\n",
    "\n",
    "df_test['female']=onehot_encoded[:,0]\n",
    "df_test['male']=onehot_encoded[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 3 1 3 3 1 3 3 2 3 1 3 3 3 2 3 2 3 3 2 2 3 1 3 3 3 1 3 3 1 1 3 2 1 1 3\n",
      " 3 3 3 3 2 3 2 3 3 3 3 3 3 3 3 1 2 1 1 2 3 2 3 3 1 1 3 1 3 2 3 3 3 2 3 2 3\n",
      " 3 3 3 3 2 3 3 3 3 1 2 3 3 3 1 3 3 3 1 3 3 3 1 1 2 2 3 3 1 3 3 3 3 3 3 3 1\n",
      " 3 3 3 3 3 3 2 1 3 2 3 2 2 1 3 3 3 3 3 3 3 3 2 2 2 1 1 3 1 3 3 3 3 2 2 3 3\n",
      " 2 2 2 1 3 3 3 1 3 3 3 3 3 2 3 3 3 3 1 3 1 3 1 3 3 3 1 3 3 1 2 3 3 2 3 2 3\n",
      " 1 3 1 3 3 2 2 3 2 1 1 3 3 3 2 3 3 3 3 3 3 3 3 3 1 3 2 3 2 3 1 3 2 1 2 3 2\n",
      " 3 3 1 3 2 3 2 3 1 3 2 3 2 3 2 2 2 2 3 3 2 3 3 1 3 2 1 2 3 3 1 3 3 3 1 1 1\n",
      " 2 3 3 1 1 3 2 3 3 1 1 1 3 2 1 3 1 3 2 3 3 3 3 3 3 1 3 3 3 2 3 1 1 2 3 3 1\n",
      " 3 1 1 1 3 3 3 2 3 1 1 1 2 1 1 1 2 3 2 3 2 2 1 1 3 3 2 2 3 1 3 2 3 1 3 1 1\n",
      " 3 1 3 1 1 3 1 2 1 2 2 2 2 2 3 3 3 3 1 3 3 3 3 1 2 3 3 3 2 3 3 3 3 1 3 3 1\n",
      " 1 3 3 1 3 1 3 1 3 3 1 3 3 1 3 2 3 2 3 2 1 3 3 1 3 3 3 2 2 2 3 3 3 3 3 2 3\n",
      " 2 3 3 3 3 1 2 3 3 2 2 2 3 3 3 3 3 3 3 2 2 3 3 1 3 2 3 1 1 3 2 1 2 2 3 3 2\n",
      " 3 1 2 1 3 1 2 3 1 1 3 3 1 1 2 3 1 3 1 2 3 3 2 1 3 3 3 3 2 2 3 1 2 3 3 3 3\n",
      " 2 3 3 1 3 1 1 3 3 3 3 1 1 3 3 1 3 1 3 3 3 3 3 1 1 2 1 3 3 3 3 1 1 3 1 2 3\n",
      " 2 3 1 3 3 1 3 3 2 1 3 2 2 3 3 3 3 2 1 1 3 1 1 3 3 2 1 1 2 2 3 2 1 2 3 3 3\n",
      " 1 1 1 1 3 3 3 2 3 3 3 3 3 3 3 2 1 1 3 3 3 2 1 3 3 2 1 2 1 3 1 2 1 3 3 3 1\n",
      " 3 3 2 3 2 3 3 1 2 3 1 3 1 3 3 1 2 1 3 3 3 3 3 2 3 3 2 2 3 1 3 3 3 1 2 1 3\n",
      " 3 1 3 1 1 3 2 3 2 3 3 3 1 3 3 3 1 3 1 3 3 3 2 3 3 3 2 3 3 2 1 1 3 1 3 3 2\n",
      " 2 3 3 1 2 1 2 2 2 3 3 3 3 1 3 1 3 3 2 2 3 3 3 1 1 3 3 3 1 2 3 3 1 3 1 1 3\n",
      " 3 3 2 2 1 1 3 1 1 1 3 2 3 1 2 3 3 2 3 2 2 1 3 2 3 2 3 1 3 2 2 2 3 3 1 3 3\n",
      " 1 1 1 3 3 1 3 2 1 3 2 3 3 3 2 2 3 2 3 1 3 3 3 1 3 1 1 3 3 3 3 3 2 3 2 3 3\n",
      " 3 3 1 3 1 1 3 3 3 3 3 3 1 3 2 3 1 3 2 1 3 3 3 2 2 1 3 3 3 1 3 2 1 3 3 2 3\n",
      " 3 1 3 2 3 3 1 3 1 3 3 3 3 2 3 1 3 2 3 3 3 1 3 3 3 1 3 2 1 3 3 3 3 3 2 1 3\n",
      " 3 3 1 2 3 1 1 3 3 3 2 1 3 2 2 2 1 3 3 3 1 1 3 2 3 3 3 3 1 2 3 3 2 3 3 2 1\n",
      " 3 1 3]\n",
      "[2 0 2 0 2 2 0 2 2 1 2 0 2 2 2 1 2 1 2 2 1 1 2 0 2 2 2 0 2 2 0 0 2 1 0 0 2\n",
      " 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 0 1 0 0 1 2 1 2 2 0 0 2 0 2 1 2 2 2 1 2 1 2\n",
      " 2 2 2 2 1 2 2 2 2 0 1 2 2 2 0 2 2 2 0 2 2 2 0 0 1 1 2 2 0 2 2 2 2 2 2 2 0\n",
      " 2 2 2 2 2 2 1 0 2 1 2 1 1 0 2 2 2 2 2 2 2 2 1 1 1 0 0 2 0 2 2 2 2 1 1 2 2\n",
      " 1 1 1 0 2 2 2 0 2 2 2 2 2 1 2 2 2 2 0 2 0 2 0 2 2 2 0 2 2 0 1 2 2 1 2 1 2\n",
      " 0 2 0 2 2 1 1 2 1 0 0 2 2 2 1 2 2 2 2 2 2 2 2 2 0 2 1 2 1 2 0 2 1 0 1 2 1\n",
      " 2 2 0 2 1 2 1 2 0 2 1 2 1 2 1 1 1 1 2 2 1 2 2 0 2 1 0 1 2 2 0 2 2 2 0 0 0\n",
      " 1 2 2 0 0 2 1 2 2 0 0 0 2 1 0 2 0 2 1 2 2 2 2 2 2 0 2 2 2 1 2 0 0 1 2 2 0\n",
      " 2 0 0 0 2 2 2 1 2 0 0 0 1 0 0 0 1 2 1 2 1 1 0 0 2 2 1 1 2 0 2 1 2 0 2 0 0\n",
      " 2 0 2 0 0 2 0 1 0 1 1 1 1 1 2 2 2 2 0 2 2 2 2 0 1 2 2 2 1 2 2 2 2 0 2 2 0\n",
      " 0 2 2 0 2 0 2 0 2 2 0 2 2 0 2 1 2 1 2 1 0 2 2 0 2 2 2 1 1 1 2 2 2 2 2 1 2\n",
      " 1 2 2 2 2 0 1 2 2 1 1 1 2 2 2 2 2 2 2 1 1 2 2 0 2 1 2 0 0 2 1 0 1 1 2 2 1\n",
      " 2 0 1 0 2 0 1 2 0 0 2 2 0 0 1 2 0 2 0 1 2 2 1 0 2 2 2 2 1 1 2 0 1 2 2 2 2\n",
      " 1 2 2 0 2 0 0 2 2 2 2 0 0 2 2 0 2 0 2 2 2 2 2 0 0 1 0 2 2 2 2 0 0 2 0 1 2\n",
      " 1 2 0 2 2 0 2 2 1 0 2 1 1 2 2 2 2 1 0 0 2 0 0 2 2 1 0 0 1 1 2 1 0 1 2 2 2\n",
      " 0 0 0 0 2 2 2 1 2 2 2 2 2 2 2 1 0 0 2 2 2 1 0 2 2 1 0 1 0 2 0 1 0 2 2 2 0\n",
      " 2 2 1 2 1 2 2 0 1 2 0 2 0 2 2 0 1 0 2 2 2 2 2 1 2 2 1 1 2 0 2 2 2 0 1 0 2\n",
      " 2 0 2 0 0 2 1 2 1 2 2 2 0 2 2 2 0 2 0 2 2 2 1 2 2 2 1 2 2 1 0 0 2 0 2 2 1\n",
      " 1 2 2 0 1 0 1 1 1 2 2 2 2 0 2 0 2 2 1 1 2 2 2 0 0 2 2 2 0 1 2 2 0 2 0 0 2\n",
      " 2 2 1 1 0 0 2 0 0 0 2 1 2 0 1 2 2 1 2 1 1 0 2 1 2 1 2 0 2 1 1 1 2 2 0 2 2\n",
      " 0 0 0 2 2 0 2 1 0 2 1 2 2 2 1 1 2 1 2 0 2 2 2 0 2 0 0 2 2 2 2 2 1 2 1 2 2\n",
      " 2 2 0 2 0 0 2 2 2 2 2 2 0 2 1 2 0 2 1 0 2 2 2 1 1 0 2 2 2 0 2 1 0 2 2 1 2\n",
      " 2 0 2 1 2 2 0 2 0 2 2 2 2 1 2 0 2 1 2 2 2 0 2 2 2 0 2 1 0 2 2 2 2 2 1 0 2\n",
      " 2 2 0 1 2 0 0 2 2 2 1 0 2 1 1 1 0 2 2 2 0 0 2 1 2 2 2 2 0 1 2 2 1 2 2 1 0\n",
      " 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "# ---------Pclass---\n",
    "values = array(df_train['Pclass'])\n",
    "print(values)\n",
    "onehot_encoded = hot_encode_PC(values)\n",
    "\n",
    "df_train['Pclass1']=onehot_encoded[:,0]\n",
    "df_train['Pclass2']=onehot_encoded[:,1]\n",
    "df_train['Pclass3']=onehot_encoded[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 2 3 3 3 3 2 3 3 3 1 1 2 1 2 2 3 3 3 1 3 1 1 1 3 1 3 1 3 2 2 3 3 1 3 3\n",
      " 3 3 3 3 1 3 2 1 3 1 3 1 3 1 2 2 1 2 3 3 3 3 1 3 2 3 3 1 2 3 1 1 1 3 3 3 1\n",
      " 1 1 3 1 2 3 3 1 1 3 2 3 3 3 3 2 3 3 1 3 1 3 1 3 3 3 1 2 3 3 3 3 3 3 3 2 2\n",
      " 3 1 3 1 3 3 3 1 2 2 3 1 3 3 3 3 3 2 3 3 1 3 3 3 3 3 2 3 3 3 1 1 2 1 3 1 3\n",
      " 1 2 1 3 3 3 3 3 1 3 1 3 3 3 2 3 2 3 1 3 1 3 3 3 3 3 3 2 2 1 2 1 2 1 1 3 1\n",
      " 2 2 3 3 2 2 1 3 2 2 3 1 3 2 3 3 3 1 2 2 1 3 2 1 3 3 3 2 2 3 1 3 1 1 3 2 3\n",
      " 2 3 1 3 3 3 3 2 2 1 3 3 1 3 1 3 2 1 1 2 1 3 3 1 2 2 2 3 2 3 1 3 3 3 3 3 2\n",
      " 3 3 3 2 3 2 3 1 3 3 3 1 3 1 3 3 2 2 2 2 2 3 3 3 3 3 3 3 1 3 3 1 3 3 1 3 3\n",
      " 2 3 1 3 3 2 2 3 3 1 1 3 1 3 3 3 3 3 1 3 1 2 3 2 3 3 2 1 1 3 2 1 2 2 2 1 3\n",
      " 3 3 1 2 3 2 3 2 3 3 1 3 3 2 3 2 2 1 2 2 2 3 1 1 3 3 3 3 2 2 3 1 3 3 3 1 2\n",
      " 2 1 1 2 1 1 3 2 1 3 3 3 3 3 2 2 3 2 3 3 1 1 3 2 3 1 3 1 3 3 1 2 1 1 1 2 2\n",
      " 1 3 3 3 1 3 3 1 3 3 3]\n",
      "[2 2 1 2 2 2 2 1 2 2 2 0 0 1 0 1 1 2 2 2 0 2 0 0 0 2 0 2 0 2 1 1 2 2 0 2 2\n",
      " 2 2 2 2 0 2 1 0 2 0 2 0 2 0 1 1 0 1 2 2 2 2 0 2 1 2 2 0 1 2 0 0 0 2 2 2 0\n",
      " 0 0 2 0 1 2 2 0 0 2 1 2 2 2 2 1 2 2 0 2 0 2 0 2 2 2 0 1 2 2 2 2 2 2 2 1 1\n",
      " 2 0 2 0 2 2 2 0 1 1 2 0 2 2 2 2 2 1 2 2 0 2 2 2 2 2 1 2 2 2 0 0 1 0 2 0 2\n",
      " 0 1 0 2 2 2 2 2 0 2 0 2 2 2 1 2 1 2 0 2 0 2 2 2 2 2 2 1 1 0 1 0 1 0 0 2 0\n",
      " 1 1 2 2 1 1 0 2 1 1 2 0 2 1 2 2 2 0 1 1 0 2 1 0 2 2 2 1 1 2 0 2 0 0 2 1 2\n",
      " 1 2 0 2 2 2 2 1 1 0 2 2 0 2 0 2 1 0 0 1 0 2 2 0 1 1 1 2 1 2 0 2 2 2 2 2 1\n",
      " 2 2 2 1 2 1 2 0 2 2 2 0 2 0 2 2 1 1 1 1 1 2 2 2 2 2 2 2 0 2 2 0 2 2 0 2 2\n",
      " 1 2 0 2 2 1 1 2 2 0 0 2 0 2 2 2 2 2 0 2 0 1 2 1 2 2 1 0 0 2 1 0 1 1 1 0 2\n",
      " 2 2 0 1 2 1 2 1 2 2 0 2 2 1 2 1 1 0 1 1 1 2 0 0 2 2 2 2 1 1 2 0 2 2 2 0 1\n",
      " 1 0 0 1 0 0 2 1 0 2 2 2 2 2 1 1 2 1 2 2 0 0 2 1 2 0 2 0 2 2 0 1 0 0 0 1 1\n",
      " 0 2 2 2 0 2 2 0 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# ---------Pclass---\n",
    "values = array(df_test['Pclass'])\n",
    "print(values)\n",
    "onehot_encoded = hot_encode_PC(values)\n",
    "\n",
    "df_test['Pclass1']=onehot_encoded[:,0]\n",
    "df_test['Pclass2']=onehot_encoded[:,1]\n",
    "df_test['Pclass3']=onehot_encoded[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 3 4 2 5 8]\n",
      "[1 1 0 1 0 0 0 3 0 1 1 0 0 1 0 0 4 0 1 0 0 0 0 0 3 1 0 3 0 0 0 1 0 0 1 1 0\n",
      " 0 2 1 1 1 0 1 0 0 1 0 2 1 4 0 1 1 0 0 0 0 1 5 0 0 1 3 0 1 0 0 4 2 0 5 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 3 1 0 3 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 2 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 1 0 4 2 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 2\n",
      " 0 0 0 1 0 0 0 0 0 0 0 8 0 0 0 0 4 0 0 1 0 0 0 4 1 0 0 1 3 0 0 0 8 0 4 2 0\n",
      " 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 8 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 3 1 0 0 4 0 0 1 0 0 0 1 1 0 0 0 2 0 0 1 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 4 1 0 0 0 4 1 0 0 0 0 0 0 0 1 0 0 4 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 2 0 0 0 1 0 1 1 0 0 2 1 0 1 0 1 0 0 1 0 0 0 1 8 0 0 0 1 0 2 0 0\n",
      " 2 1 0 1 0 0 0 1 3 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0\n",
      " 1 1 0 0 3 1 0 0 0 0 0 0 0 1 0 0 5 0 0 0 1 0 2 1 0 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 1 0 3 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 2 2 1 0 1 0 1 0\n",
      " 0 0 0 0 2 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0 0 1 1 0 0 5\n",
      " 0 0 0 1 3 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 2 1 0 1 0 0 0 0 0 0 0 0 4 4 1 1 0 1 0 1 1 0 0 0 0 0\n",
      " 0 1 0 1 1 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 1 1 0 0 0 1 2 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 2 0 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 3 0 0 1 0 1 0 0 3 0 2 1 0 0 0 0 0 0 0 0 0 2 0 1 0 0 2 0 0 0 1 2\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 5 1 1 4 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 3 0 1 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 2 1 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 4 1 0 0 0 8 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 4\n",
      " 0 0 0 1 0 3 1 0 0 0 4 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 8 0 0 1 4\n",
      " 0 1 0 1 0 1 0 0 0 2 1 0 8 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0]\n",
      "[1 1 0 1 0 0 0 3 0 1 1 0 0 1 0 0 4 0 1 0 0 0 0 0 3 1 0 3 0 0 0 1 0 0 1 1 0\n",
      " 0 2 1 1 1 0 1 0 0 1 0 2 1 4 0 1 1 0 0 0 0 1 5 0 0 1 3 0 1 0 0 4 2 0 5 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 3 1 0 3 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 2 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 1 0 4 2 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 2\n",
      " 0 0 0 1 0 0 0 0 0 0 0 6 0 0 0 0 4 0 0 1 0 0 0 4 1 0 0 1 3 0 0 0 6 0 4 2 0\n",
      " 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 6 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 3 1 0 0 4 0 0 1 0 0 0 1 1 0 0 0 2 0 0 1 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 4 1 0 0 0 4 1 0 0 0 0 0 0 0 1 0 0 4 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 2 0 0 0 1 0 1 1 0 0 2 1 0 1 0 1 0 0 1 0 0 0 1 6 0 0 0 1 0 2 0 0\n",
      " 2 1 0 1 0 0 0 1 3 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0\n",
      " 1 1 0 0 3 1 0 0 0 0 0 0 0 1 0 0 5 0 0 0 1 0 2 1 0 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 1 0 3 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 2 2 1 0 1 0 1 0\n",
      " 0 0 0 0 2 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0 0 1 1 0 0 5\n",
      " 0 0 0 1 3 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 2 1 0 1 0 0 0 0 0 0 0 0 4 4 1 1 0 1 0 1 1 0 0 0 0 0\n",
      " 0 1 0 1 1 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 1 1 0 0 0 1 2 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 2 0 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 3 0 0 1 0 1 0 0 3 0 2 1 0 0 0 0 0 0 0 0 0 2 0 1 0 0 2 0 0 0 1 2\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 5 1 1 4 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 3 0 1 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 2 1 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 4 1 0 0 0 6 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 4\n",
      " 0 0 0 1 0 3 1 0 0 0 4 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 6 0 0 1 4\n",
      " 0 1 0 1 0 1 0 0 0 2 1 0 6 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# ---------SibSP--- TRAIN\n",
    "del values\n",
    "print (df_train['SibSp'].unique())\n",
    "values = array(df_train['SibSp'])\n",
    "print(values)\n",
    "onehot_encoded = hot_encode_PC(values)\n",
    "\n",
    "df_train['SibSp0']=onehot_encoded[:,0]\n",
    "df_train['SibSp1']=onehot_encoded[:,1]\n",
    "df_train['SibSp2']=onehot_encoded[:,2]\n",
    "df_train['SibSp3']=onehot_encoded[:,3]\n",
    "df_train['SibSp4']=onehot_encoded[:,4]\n",
    "df_train['SibSp5']=onehot_encoded[:,5]\n",
    "df_train['SibSp8']=onehot_encoded[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 8]\n",
      "[0 1 0 0 1 0 0 1 0 2 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 2 1 2 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 2 3 0 4 0 0 1 0 0 0 0 0 2 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 2 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 1 0 1 1 0 0 0 0 2 0 0 0 0 0 1 0 0 0 0 0 1 5 0 1 0 0 3 0 0\n",
      " 0 1 0 0 0 0 4 0 0 0 0 0 0 1 0 0 0 1 0 2 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1\n",
      " 0 0 2 8 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 4 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0\n",
      " 1 2 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 2 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 2 0 0 1 8 1 0 0 1 1 1 0 0 0\n",
      " 1 0 0 0 1 0 2 0 0 4 0 0 0 1 0 1 0 0 0 3 0 0 0 0 3 1 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 0 1 0 1 0 0 0 0 0 1]\n",
      "[0 1 0 0 1 0 0 1 0 2 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 2 1 2 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 2 3 0 4 0 0 1 0 0 0 0 0 2 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 2 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 1 0 1 1 0 0 0 0 2 0 0 0 0 0 1 0 0 0 0 0 1 5 0 1 0 0 3 0 0\n",
      " 0 1 0 0 0 0 4 0 0 0 0 0 0 1 0 0 0 1 0 2 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1\n",
      " 0 0 2 6 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 4 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0\n",
      " 1 2 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 2 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 2 0 0 1 6 1 0 0 1 1 1 0 0 0\n",
      " 1 0 0 0 1 0 2 0 0 4 0 0 0 1 0 1 0 0 0 3 0 0 0 0 3 1 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 0 1 0 1 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# ---------SibSP--- TEST\n",
    "del values\n",
    "print (df_test['SibSp'].unique())\n",
    "values = array(df_test['SibSp'])\n",
    "print(values)\n",
    "onehot_encoded = hot_encode_PC(values)\n",
    "\n",
    "df_test['SibSp0']=onehot_encoded[:,0]\n",
    "df_test['SibSp1']=onehot_encoded[:,1]\n",
    "df_test['SibSp2']=onehot_encoded[:,2]\n",
    "df_test['SibSp3']=onehot_encoded[:,3]\n",
    "df_test['SibSp4']=onehot_encoded[:,4]\n",
    "df_test['SibSp5']=onehot_encoded[:,5]\n",
    "df_test['SibSp8']=onehot_encoded[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 5 3 4 6]\n",
      "[0 0 0 0 0 0 0 1 2 0 1 0 0 5 0 0 1 0 0 0 0 0 0 0 1 5 0 2 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 1 0 0 0 2 2 0 0 0 2 0 1 0 0 2 0 0 2 0 0\n",
      " 0 0 0 0 2 0 0 0 0 0 0 0 3 0 2 0 0 0 0 2 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 1 0 2\n",
      " 2 0 0 0 0 2 0 1 0 0 0 2 1 0 0 0 1 2 1 4 0 0 0 1 1 0 0 1 1 0 0 0 2 0 2 1 2\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 2 1 0 0 1 0 0 2 2 0 0 0\n",
      " 1 0 2 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 2 0 1 0 0 0 0 0 2 0 0 0 0 0 2 1 0 1 0 0 0 2 1 0 0 0 1 2 0 0 0 1 1 0 0 1\n",
      " 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 4 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 2 0 0 0 2 0 0 0 0 2 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 1 2 0 2 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 2 2 3 4 0 1 0 0 0\n",
      " 0 2 1 0 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 1 2\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 2 0 2 0 0 0 2 2 2 2 0 0 0 0 0 1 1 2 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 2 0 1 0 0 0 0\n",
      " 0 2 0 1 0 0 0 0 1 0 0 0 0 0 0 0 2 0 5 0 0 0 0 2 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 2 0 0 1 5 0 0 0 2 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 2 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 6 1 0 0 0 2 1 2 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0\n",
      " 0 0 2 0 0 1 1 0 0 0 1 1 0 0 2 1 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 3 0 0\n",
      " 0 0 1 0 0 0 2 0 0 0 1 2 0 0 0 2 0 0 0 0 0 0 1 0 1 2 1 0 0 0 0 0 0 0 0 0 2\n",
      " 0 0 0 1 0 2 1 0 0 1 1 0 0 2 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 2 0 1 0 2\n",
      " 0 1 1 0 1 1 0 3 0 0 0 0 2 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 5 0 0\n",
      " 2 0 0]\n",
      "[0 0 0 0 0 0 0 1 2 0 1 0 0 5 0 0 1 0 0 0 0 0 0 0 1 5 0 2 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 1 0 0 0 2 2 0 0 0 2 0 1 0 0 2 0 0 2 0 0\n",
      " 0 0 0 0 2 0 0 0 0 0 0 0 3 0 2 0 0 0 0 2 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 1 0 2\n",
      " 2 0 0 0 0 2 0 1 0 0 0 2 1 0 0 0 1 2 1 4 0 0 0 1 1 0 0 1 1 0 0 0 2 0 2 1 2\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 2 1 0 0 1 0 0 2 2 0 0 0\n",
      " 1 0 2 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 2 0 1 0 0 0 0 0 2 0 0 0 0 0 2 1 0 1 0 0 0 2 1 0 0 0 1 2 0 0 0 1 1 0 0 1\n",
      " 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 4 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 2 0 0 0 2 0 0 0 0 2 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 1 2 0 2 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 2 2 3 4 0 1 0 0 0\n",
      " 0 2 1 0 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 1 2\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 2 0 2 0 0 0 2 2 2 2 0 0 0 0 0 1 1 2 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 2 0 1 0 0 0 0\n",
      " 0 2 0 1 0 0 0 0 1 0 0 0 0 0 0 0 2 0 5 0 0 0 0 2 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 2 0 0 1 5 0 0 0 2 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 2 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 6 1 0 0 0 2 1 2 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0\n",
      " 0 0 2 0 0 1 1 0 0 0 1 1 0 0 2 1 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 3 0 0\n",
      " 0 0 1 0 0 0 2 0 0 0 1 2 0 0 0 2 0 0 0 0 0 0 1 0 1 2 1 0 0 0 0 0 0 0 0 0 2\n",
      " 0 0 0 1 0 2 1 0 0 1 1 0 0 2 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 2 0 1 0 2\n",
      " 0 1 1 0 1 1 0 3 0 0 0 0 2 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 5 0 0\n",
      " 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# ---------Parch--- TRAIN\n",
    "del values\n",
    "print (df_train['Parch'].unique())\n",
    "values = array(df_train['Parch'])\n",
    "print(values)\n",
    "onehot_encoded = hot_encode_PC(values)\n",
    "\n",
    "df_train['Parch0']=onehot_encoded[:,0]\n",
    "df_train['Parch1']=onehot_encoded[:,1]\n",
    "df_train['Parch2']=onehot_encoded[:,2]\n",
    "df_train['Parch3']=onehot_encoded[:,3]\n",
    "df_train['Parch4']=onehot_encoded[:,4]\n",
    "df_train['Parch5']=onehot_encoded[:,5]\n",
    "df_train['Parch6']=onehot_encoded[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 3 2 4 6 5 9]\n",
      "[0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 3 0 1 0 0 0 0 0 2 2 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 1 2 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 4 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 4 0 0 0 0 0 0 6 2 0 3 0 0 0 0 0\n",
      " 0 1 1 0 0 2 2 0 0 0 0 2 0 1 0 0 0 1 0 2 0 0 0 0 0 0 5 2 0 0 3 2 0 1 0 0 1\n",
      " 0 1 0 2 0 0 0 1 0 2 0 2 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 2 0 0 1 1 0 0 0\n",
      " 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 1 0 2 0 0 1 0 0 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 2 0 0 0 0 0 1 0 0 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 0 0\n",
      " 1 0 0 0 2 0 0 0 0 9 1 1 0 0 0 0 0 1 0 0 2 2 0 0 0 0 0 2 1 0 0 0 9 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 2 0 0 0 1 0 1 2 0 1 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 3 0 1 0 0 0 0 0 2 2 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 1 2 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 4 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 4 0 0 0 0 0 0 6 2 0 3 0 0 0 0 0\n",
      " 0 1 1 0 0 2 2 0 0 0 0 2 0 1 0 0 0 1 0 2 0 0 0 0 0 0 5 2 0 0 3 2 0 1 0 0 1\n",
      " 0 1 0 2 0 0 0 1 0 2 0 2 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 2 0 0 1 1 0 0 0\n",
      " 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 1 0 2 0 0 1 0 0 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 2 0 0 0 0 0 1 0 0 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 0 0\n",
      " 1 0 0 0 2 0 0 0 0 7 1 1 0 0 0 0 0 1 0 0 2 2 0 0 0 0 0 2 1 0 0 0 7 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 2 0 0 0 1 0 1 2 0 1 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# ---------Parch--- TEST\n",
    "# Apareix un 9 que no se que es, aquest el deixarem sense omplir\n",
    "del values\n",
    "print (df_test['Parch'].unique())\n",
    "values = array(df_test['Parch'])\n",
    "print(values)\n",
    "onehot_encoded = hot_encode_PC(values)\n",
    "\n",
    "df_test['Parch0']=onehot_encoded[:,0]\n",
    "df_test['Parch1']=onehot_encoded[:,1]\n",
    "df_test['Parch2']=onehot_encoded[:,2]\n",
    "df_test['Parch3']=onehot_encoded[:,3]\n",
    "df_test['Parch4']=onehot_encoded[:,4]\n",
    "df_test['Parch5']=onehot_encoded[:,5]\n",
    "df_test['Parch6']=onehot_encoded[:,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ara afegiria una categoritzacio del FARE (sembla que te certa correlacio amb supervivencia)\n",
    "Al test, el Fare te 1 NaN... podriem veure quina classe es, i li posem la mitja en funcio de la classe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df_train['Fare'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.6271884892086\n",
      "Pclass\n",
      "1    94.280297\n",
      "2    22.202104\n",
      "3    12.459678\n",
      "Name: Fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (df_test['Fare'].mean())\n",
    "print (df_test.groupby(['Pclass'])['Fare'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Pclass                Name   Sex   Age  SibSp  Parch Ticket  \\\n",
      "152         1044       3  Storey, Mr. Thomas  male  60.5      0      0   3701   \n",
      "\n",
      "     Fare Cabin Embarked Deck  Number  Deck_A  Deck_B  Deck_C  Deck_D  Deck_E  \\\n",
      "152   NaN   NaN        S    X     NaN     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "     Deck_F  Deck_G  Deck_X AgeGroup  adult  bebe  infant  jove  nen  vell  \\\n",
      "152     0.0     0.0     1.0     vell    0.0   0.0     0.0   0.0  0.0   1.0   \n",
      "\n",
      "     female  male  Pclass1  Pclass2  Pclass3  SibSp0  SibSp1  SibSp2  SibSp3  \\\n",
      "152     0.0   1.0      0.0      0.0      1.0     1.0     0.0     0.0     0.0   \n",
      "\n",
      "     SibSp4  SibSp5  SibSp8  Parch0  Parch1  Parch2  Parch3  Parch4  Parch5  \\\n",
      "152     0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "     Parch6  \n",
      "152     0.0  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 47)\n",
    "print(df_test[df_test['Fare'].isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El que tenim sense dades es de 3 classe, posem el valor de fare mig per pclass==3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_test['Fare'][df_test['Fare'].isnull()] = 12.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Fare FareGroup\n",
      "0      7.2500        20\n",
      "1     71.2833        80\n",
      "2      7.9250        20\n",
      "3     53.1000        60\n",
      "4      8.0500        20\n",
      "5      8.4583        20\n",
      "6     51.8625        60\n",
      "7     21.0750        40\n",
      "8     11.1333        20\n",
      "9     30.0708        40\n",
      "10    16.7000        20\n",
      "11    26.5500        40\n",
      "12     8.0500        20\n",
      "13    31.2750        40\n",
      "14     7.8542        20\n",
      "15    16.0000        20\n",
      "16    29.1250        40\n",
      "17    13.0000        20\n",
      "18    18.0000        20\n",
      "19     7.2250        20\n",
      "20    26.0000        40\n",
      "21    13.0000        20\n",
      "22     8.0292        20\n",
      "23    35.5000        40\n",
      "24    21.0750        40\n",
      "25    31.3875        40\n",
      "26     7.2250        20\n",
      "27   263.0000       300\n",
      "28     7.8792        20\n",
      "29     7.8958        20\n",
      "..        ...       ...\n",
      "861   11.5000        20\n",
      "862   25.9292        40\n",
      "863   69.5500        80\n",
      "864   13.0000        20\n",
      "865   13.0000        20\n",
      "866   13.8583        20\n",
      "867   50.4958        60\n",
      "868    9.5000        20\n",
      "869   11.1333        20\n",
      "870    7.8958        20\n",
      "871   52.5542        60\n",
      "872    5.0000        20\n",
      "873    9.0000        20\n",
      "874   24.0000        40\n",
      "875    7.2250        20\n",
      "876    9.8458        20\n",
      "877    7.8958        20\n",
      "878    7.8958        20\n",
      "879   83.1583       100\n",
      "880   26.0000        40\n",
      "881    7.8958        20\n",
      "882   10.5167        20\n",
      "883   10.5000        20\n",
      "884    7.0500        20\n",
      "885   29.1250        40\n",
      "886   13.0000        20\n",
      "887   30.0000        40\n",
      "888   23.4500        40\n",
      "889   30.0000        40\n",
      "890    7.7500        20\n",
      "\n",
      "[891 rows x 2 columns]\n",
      "[20, 80, 60, 40, 300, 200, 100, 600]\n",
      "Categories (8, object): [20 < 40 < 60 < 80 < 100 < 200 < 300 < 600]\n",
      "['20' '80' '20' '60' '20' '20' '60' '40' '20' '40' '20' '40' '20' '40'\n",
      " '20' '20' '40' '20' '20' '20' '40' '20' '20' '40' '40' '40' '20' '300'\n",
      " '20' '20' '40' '200' '20' '20' '100' '60' '20' '20' '20' '20' '20' '40'\n",
      " '20' '60' '20' '20' '20' '20' '40' '20' '40' '20' '80' '40' '80' '40'\n",
      " '20' '20' '40' '60' '20' '100' '100' '40' '40' '20' '20' '20' '20' '20'\n",
      " '20' '60' '80' '20' '60' '20' '20' '20' '40' '20' '20' '20' '20' '60'\n",
      " '20' '20' '40' '20' '300' '20' '20' '20' '80' '40' '20' '20' '40' '80'\n",
      " '40' '40' '20' '20' '80' '20' '20' '20' '20' '20' '20' '40' '60' '20'\n",
      " '20' '20' '20' '20' '20' '40' '300' '40' '80' '20' '40' '20' '80' '20'\n",
      " '20' '20' '40' '20' '20' '20' '20' '40' '20' '20' '40' '60' '20' '80'\n",
      " '20' '20' '20' '20' '20' '40' '20' '40' '40' '20' '20' '80' '20' '20'\n",
      " '20' '80' '20' '20' '20' '80' '20' '20' '20' '20' '40' '40' '60' '40'\n",
      " '40' '60' '40' '40' '20' '20' '40' '20' '40' '40' '20' '20' '80' '20'\n",
      " '40' '40' '40' '60' '20' '40' '20' '20' '20' '20' '20' '40' '40' '200'\n",
      " '20' '20' '20' '20' '20' '80' '20' '20' '20' '20' '20' '20' '20' '40'\n",
      " '20' '40' '20' '20' '20' '200' '20' '40' '80' '20' '20' '20' '20' '20'\n",
      " '100' '20' '20' '20' '20' '40' '100' '20' '20' '40' '20' '20' '40' '40'\n",
      " '20' '20' '20' '20' '20' '20' '20' '100' '20' '20' '60' '40' '20' '20'\n",
      " '40' '20' '40' '20' '80' '100' '600' '40' '20' '40' '80' '20' '20' '20'\n",
      " '40' '20' '200' '200' '40' '20' '20' '40' '20' '80' '20' '20' '40' '40'\n",
      " '20' '20' '20' '20' '40' '20' '20' '20' '20' '20' '80' '100' '20' '20'\n",
      " '20' '40' '20' '200' '40' '300' '20' '40' '20' '20' '20' '200' '200'\n",
      " '200' '40' '60' '100' '300' '40' '20' '40' '20' '40' '20' '200' '200'\n",
      " '20' '20' '20' '40' '80' '200' '20' '20' '40' '60' '40' '40' '200' '20'\n",
      " '200' '20' '80' '200' '20' '40' '40' '300' '20' '20' '20' '20' '20' '20'\n",
      " '20' '20' '20' '40' '20' '20' '20' '20' '60' '20' '20' '20' '40' '40'\n",
      " '20' '20' '20' '20' '80' '20' '20' '80' '60' '20' '20' '200' '40' '100'\n",
      " '20' '300' '20' '20' '300' '20' '20' '60' '20' '80' '60' '20' '20' '20'\n",
      " '200' '20' '20' '200' '20' '20' '20' '40' '20' '20' '20' '20' '20' '20'\n",
      " '20' '40' '20' '20' '20' '40' '20' '20' '100' '20' '20' '20' '40' '20'\n",
      " '20' '40' '20' '20' '20' '20' '40' '20' '40' '40' '20' '20' '40' '20'\n",
      " '40' '20' '60' '200' '40' '20' '300' '20' '40' '20' '20' '20' '20' '100'\n",
      " '20' '40' '20' '40' '40' '20' '40' '100' '20' '20' '40' '60' '20' '20'\n",
      " '40' '20' '40' '20' '20' '20' '20' '40' '20' '20' '20' '20' '40' '20'\n",
      " '20' '60' '40' '20' '20' '20' '60' '20' '20' '20' '100' '40' '100' '40'\n",
      " '20' '20' '20' '20' '40' '60' '20' '20' '80' '20' '200' '20' '20' '20'\n",
      " '20' '20' '100' '200' '40' '40' '40' '60' '20' '20' '40' '60' '20' '40'\n",
      " '20' '40' '40' '20' '100' '20' '20' '60' '20' '20' '20' '300' '20' '20'\n",
      " '40' '20' '20' '40' '20' '40' '40' '200' '20' '60' '80' '40' '40' '40'\n",
      " '200' '40' '40' '20' '40' '40' '200' '40' '20' '20' '20' '40' '40' '300'\n",
      " '80' '20' '20' '20' '20' '20' '20' '40' '20' '40' '20' '20' '20' '60'\n",
      " '40' '20' '20' '20' '20' '60' '20' '20' '40' '200' '40' '60' '20' '80'\n",
      " '20' '80' '20' '20' '20' '80' '20' '20' '40' '40' '40' '20' '20' '60'\n",
      " '40' '20' '60' '20' '40' '20' '20' '40' '60' '200' '40' '20' '20' '20'\n",
      " '20' '80' '20' '20' '40' '20' '20' '60' '20' '20' '20' '40' '20' '80'\n",
      " '20' '20' '40' '20' '40' '20' '40' '20' '20' '40' '40' '20' '20' '80'\n",
      " '40' '60' '20' '80' '20' '40' '20' '20' '20' '40' '20' '20' '20' '80'\n",
      " '20' '20' '20' '200' '200' '20' '40' '20' '20' '80' '20' '20' '20' '60'\n",
      " '40' '60' '20' '20' '20' '20' '20' '20' '60' '600' '20' '80' '20' '60'\n",
      " '40' '60' '40' '20' '20' '300' '60' '20' '60' '20' '40' '20' '20' '20'\n",
      " '200' '20' '300' '40' '20' '20' '20' '40' '20' '40' '200' '20' '60' '40'\n",
      " '60' '20' '20' '20' '300' '20' '20' '20' '40' '20' '20' '20' '60' '20'\n",
      " '40' '20' '40' '20' '300' '20' '20' '20' '20' '20' '40' '600' '20' '20'\n",
      " '40' '80' '300' '20' '20' '80' '40' '20' '60' '20' '40' '20' '20' '20'\n",
      " '80' '20' '20' '20' '20' '100' '20' '20' '20' '200' '20' '80' '40' '20'\n",
      " '40' '20' '20' '20' '20' '20' '40' '20' '20' '20' '20' '300' '20' '60'\n",
      " '40' '40' '20' '20' '20' '40' '40' '80' '20' '40' '80' '40' '20' '20'\n",
      " '40' '20' '20' '40' '20' '40' '200' '20' '20' '20' '20' '20' '20' '60'\n",
      " '20' '40' '20' '40' '20' '20' '20' '40' '20' '40' '100' '20' '20' '20'\n",
      " '40' '20' '60' '40' '20' '100' '20' '20' '20' '20' '20' '100' '20' '20'\n",
      " '60' '40' '20' '20' '40' '20' '20' '20' '80' '20' '40' '100' '40' '20'\n",
      " '20' '40' '40' '20' '200' '40' '20' '20' '20' '20' '40' '80' '20' '20'\n",
      " '20' '60' '20' '20' '20' '60' '20' '20' '40' '20' '20' '20' '20' '100'\n",
      " '40' '20' '20' '20' '20' '40' '20' '40' '40' '40' '20']\n",
      "[1 7 1 5 1 1 5 4 1 4 1 4 1 4 1 1 4 1 1 1 4 1 1 4 4 4 1 3 1 1 4 2 1 1 0 5 1\n",
      " 1 1 1 1 4 1 5 1 1 1 1 4 1 4 1 7 4 7 4 1 1 4 5 1 0 0 4 4 1 1 1 1 1 1 5 7 1\n",
      " 5 1 1 1 4 1 1 1 1 5 1 1 4 1 3 1 1 1 7 4 1 1 4 7 4 4 1 1 7 1 1 1 1 1 1 4 5\n",
      " 1 1 1 1 1 1 4 3 4 7 1 4 1 7 1 1 1 4 1 1 1 1 4 1 1 4 5 1 7 1 1 1 1 1 4 1 4\n",
      " 4 1 1 7 1 1 1 7 1 1 1 7 1 1 1 1 4 4 5 4 4 5 4 4 1 1 4 1 4 4 1 1 7 1 4 4 4\n",
      " 5 1 4 1 1 1 1 1 4 4 2 1 1 1 1 1 7 1 1 1 1 1 1 1 4 1 4 1 1 1 2 1 4 7 1 1 1\n",
      " 1 1 0 1 1 1 1 4 0 1 1 4 1 1 4 4 1 1 1 1 1 1 1 0 1 1 5 4 1 1 4 1 4 1 7 0 6\n",
      " 4 1 4 7 1 1 1 4 1 2 2 4 1 1 4 1 7 1 1 4 4 1 1 1 1 4 1 1 1 1 1 7 0 1 1 1 4\n",
      " 1 2 4 3 1 4 1 1 1 2 2 2 4 5 0 3 4 1 4 1 4 1 2 2 1 1 1 4 7 2 1 1 4 5 4 4 2\n",
      " 1 2 1 7 2 1 4 4 3 1 1 1 1 1 1 1 1 1 4 1 1 1 1 5 1 1 1 4 4 1 1 1 1 7 1 1 7\n",
      " 5 1 1 2 4 0 1 3 1 1 3 1 1 5 1 7 5 1 1 1 2 1 1 2 1 1 1 4 1 1 1 1 1 1 1 4 1\n",
      " 1 1 4 1 1 0 1 1 1 4 1 1 4 1 1 1 1 4 1 4 4 1 1 4 1 4 1 5 2 4 1 3 1 4 1 1 1\n",
      " 1 0 1 4 1 4 4 1 4 0 1 1 4 5 1 1 4 1 4 1 1 1 1 4 1 1 1 1 4 1 1 5 4 1 1 1 5\n",
      " 1 1 1 0 4 0 4 1 1 1 1 4 5 1 1 7 1 2 1 1 1 1 1 0 2 4 4 4 5 1 1 4 5 1 4 1 4\n",
      " 4 1 0 1 1 5 1 1 1 3 1 1 4 1 1 4 1 4 4 2 1 5 7 4 4 4 2 4 4 1 4 4 2 4 1 1 1\n",
      " 4 4 3 7 1 1 1 1 1 1 4 1 4 1 1 1 5 4 1 1 1 1 5 1 1 4 2 4 5 1 7 1 7 1 1 1 7\n",
      " 1 1 4 4 4 1 1 5 4 1 5 1 4 1 1 4 5 2 4 1 1 1 1 7 1 1 4 1 1 5 1 1 1 4 1 7 1\n",
      " 1 4 1 4 1 4 1 1 4 4 1 1 7 4 5 1 7 1 4 1 1 1 4 1 1 1 7 1 1 1 2 2 1 4 1 1 7\n",
      " 1 1 1 5 4 5 1 1 1 1 1 1 5 6 1 7 1 5 4 5 4 1 1 3 5 1 5 1 4 1 1 1 2 1 3 4 1\n",
      " 1 1 4 1 4 2 1 5 4 5 1 1 1 3 1 1 1 4 1 1 1 5 1 4 1 4 1 3 1 1 1 1 1 4 6 1 1\n",
      " 4 7 3 1 1 7 4 1 5 1 4 1 1 1 7 1 1 1 1 0 1 1 1 2 1 7 4 1 4 1 1 1 1 1 4 1 1\n",
      " 1 1 3 1 5 4 4 1 1 1 4 4 7 1 4 7 4 1 1 4 1 1 4 1 4 2 1 1 1 1 1 1 5 1 4 1 4\n",
      " 1 1 1 4 1 4 0 1 1 1 4 1 5 4 1 0 1 1 1 1 1 0 1 1 5 4 1 1 4 1 1 1 7 1 4 0 4\n",
      " 1 1 4 4 1 2 4 1 1 1 1 4 7 1 1 1 5 1 1 1 5 1 1 4 1 1 1 1 0 4 1 1 1 1 4 1 4\n",
      " 4 4 1]\n"
     ]
    }
   ],
   "source": [
    "# fem grups de fare en plan: 0,20,40,60,80,100,200,300,400,500,600\n",
    "# en aquest bloc definim una columna categoritzant les edats\n",
    "bins= [0,20,40,60,80,100,200,300,400,500,600]\n",
    "labels = ['20','40','60','80','100','200','300','400','500','600']\n",
    "df_train['FareGroup'] = pd.cut(df_train['Fare'], bins=bins, labels=labels, right=False)\n",
    "print(df_train[['Fare','FareGroup']])\n",
    "\n",
    "del values\n",
    "print (df_train['FareGroup'].unique())\n",
    "values = array(df_train['FareGroup'])\n",
    "print(values)\n",
    "onehot_encoded = hot_encode_PC(values)\n",
    "\n",
    "\n",
    "# ha codificat aixi: 100-0, 20-1, 200-2, 300-3,  40-4, 60-5, 600-6, 80-7\n",
    "df_train['Fare20']=onehot_encoded[:,0]\n",
    "df_train['Fare40']=onehot_encoded[:,1]\n",
    "df_train['Fare60']=onehot_encoded[:,2]\n",
    "df_train['Fare80']=onehot_encoded[:,3]\n",
    "df_train['Fare100']=onehot_encoded[:,4]\n",
    "df_train['Fare200']=onehot_encoded[:,5]\n",
    "df_train['Fare300']=onehot_encoded[:,6]\n",
    "df_train['Fare600']=onehot_encoded[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Fare FareGroup\n",
      "0      7.8292        20\n",
      "1      7.0000        20\n",
      "2      9.6875        20\n",
      "3      8.6625        20\n",
      "4     12.2875        20\n",
      "5      9.2250        20\n",
      "6      7.6292        20\n",
      "7     29.0000        40\n",
      "8      7.2292        20\n",
      "9     24.1500        40\n",
      "10     7.8958        20\n",
      "11    26.0000        40\n",
      "12    82.2667       100\n",
      "13    26.0000        40\n",
      "14    61.1750        80\n",
      "15    27.7208        40\n",
      "16    12.3500        20\n",
      "17     7.2250        20\n",
      "18     7.9250        20\n",
      "19     7.2250        20\n",
      "20    59.4000        60\n",
      "21     3.1708        20\n",
      "22    31.6833        40\n",
      "23    61.3792        80\n",
      "24   262.3750       300\n",
      "25    14.5000        20\n",
      "26    61.9792        80\n",
      "27     7.2250        20\n",
      "28    30.5000        40\n",
      "29    21.6792        40\n",
      "..        ...       ...\n",
      "388    7.7500        20\n",
      "389   21.0750        40\n",
      "390   93.5000       100\n",
      "391   39.4000        40\n",
      "392   20.2500        40\n",
      "393   10.5000        20\n",
      "394   22.0250        40\n",
      "395   60.0000        80\n",
      "396    7.2500        20\n",
      "397   79.2000        80\n",
      "398    7.7750        20\n",
      "399    7.7333        20\n",
      "400  164.8667       200\n",
      "401   21.0000        40\n",
      "402   59.4000        60\n",
      "403   47.1000        60\n",
      "404   27.7208        40\n",
      "405   13.8625        20\n",
      "406   10.5000        20\n",
      "407  211.5000       300\n",
      "408    7.7208        20\n",
      "409   13.7750        20\n",
      "410    7.7500        20\n",
      "411   90.0000       100\n",
      "412    7.7750        20\n",
      "413    8.0500        20\n",
      "414  108.9000       200\n",
      "415    7.2500        20\n",
      "416    8.0500        20\n",
      "417   22.3583        40\n",
      "\n",
      "[418 rows x 2 columns]\n",
      "[20, 40, 100, 80, 60, 300, 200, 600]\n",
      "Categories (8, object): [20 < 40 < 60 < 80 < 100 < 200 < 300 < 600]\n",
      "['20' '20' '20' '20' '20' '20' '20' '40' '20' '40' '20' '40' '100' '40'\n",
      " '80' '40' '20' '20' '20' '20' '60' '20' '40' '80' '300' '20' '80' '20'\n",
      " '40' '40' '40' '40' '40' '40' '60' '20' '20' '20' '20' '60' '20' '40'\n",
      " '20' '20' '60' '20' '40' '20' '80' '20' '80' '20' '40' '300' '20' '40'\n",
      " '20' '20' '20' '300' '20' '20' '20' '20' '300' '40' '20' '60' '40' '300'\n",
      " '20' '20' '20' '40' '300' '300' '20' '40' '20' '20' '20' '300' '40' '20'\n",
      " '20' '20' '20' '20' '20' '40' '20' '20' '60' '20' '40' '20' '80' '20'\n",
      " '20' '20' '60' '40' '20' '20' '20' '40' '20' '20' '20' '20' '20' '20'\n",
      " '40' '20' '300' '20' '20' '20' '80' '40' '20' '20' '60' '20' '20' '20'\n",
      " '20' '40' '20' '20' '20' '40' '40' '20' '20' '20' '20' '20' '20' '60'\n",
      " '60' '200' '300' '40' '40' '20' '60' '20' '40' '40' '100' '20' '20' '20'\n",
      " '40' '20' '300' '20' '40' '20' '20' '20' '20' '20' '20' '40' '60' '40'\n",
      " '40' '20' '20' '20' '20' '20' '40' '40' '40' '60' '40' '100' '20' '100'\n",
      " '60' '20' '300' '20' '40' '20' '80' '20' '40' '40' '20' '20' '40' '20'\n",
      " '200' '20' '20' '20' '20' '20' '300' '40' '20' '40' '20' '20' '40' '20'\n",
      " '40' '20' '80' '40' '20' '60' '20' '200' '300' '20' '20' '20' '20' '20'\n",
      " '40' '20' '20' '20' '20' '20' '80' '40' '20' '20' '80' '20' '80' '20'\n",
      " '20' '200' '40' '40' '200' '20' '40' '60' '40' '40' '40' '20' '40' '20'\n",
      " '200' '20' '20' '20' '20' '20' '20' '20' '20' '20' '40' '20' '20' '20'\n",
      " '20' '20' '20' '20' '80' '20' '200' '20' '20' '40' '20' '40' '40' '20'\n",
      " '20' '20' '20' '20' '40' '20' '20' '100' '20' '20' '40' '20' '20' '100'\n",
      " '20' '20' '60' '40' '60' '20' '20' '20' '40' '20' '20' '40' '200' '20'\n",
      " '100' '20' '20' '20' '20' '20' '200' '20' '200' '20' '20' '40' '20' '20'\n",
      " '20' '40' '300' '20' '40' '80' '40' '20' '40' '40' '20' '20' '20' '40'\n",
      " '20' '20' '40' '20' '20' '20' '80' '600' '20' '20' '20' '20' '20' '40'\n",
      " '80' '20' '80' '80' '40' '40' '60' '20' '20' '20' '80' '40' '40' '20'\n",
      " '60' '80' '20' '40' '60' '20' '20' '200' '20' '20' '100' '300' '20' '20'\n",
      " '60' '40' '20' '20' '20' '20' '20' '80' '20' '20' '20' '40' '100' '40'\n",
      " '40' '20' '40' '80' '20' '80' '20' '20' '200' '40' '60' '60' '40' '20'\n",
      " '20' '300' '20' '20' '20' '100' '20' '20' '200' '20' '20' '40']\n",
      "[1 1 1 1 1 1 1 4 1 4 1 4 0 4 7 4 1 1 1 1 5 1 4 7 3 1 7 1 4 4 4 4 4 4 5 1 1\n",
      " 1 1 5 1 4 1 1 5 1 4 1 7 1 7 1 4 3 1 4 1 1 1 3 1 1 1 1 3 4 1 5 4 3 1 1 1 4\n",
      " 3 3 1 4 1 1 1 3 4 1 1 1 1 1 1 4 1 1 5 1 4 1 7 1 1 1 5 4 1 1 1 4 1 1 1 1 1\n",
      " 1 4 1 3 1 1 1 7 4 1 1 5 1 1 1 1 4 1 1 1 4 4 1 1 1 1 1 1 5 5 2 3 4 4 1 5 1\n",
      " 4 4 0 1 1 1 4 1 3 1 4 1 1 1 1 1 1 4 5 4 4 1 1 1 1 1 4 4 4 5 4 0 1 0 5 1 3\n",
      " 1 4 1 7 1 4 4 1 1 4 1 2 1 1 1 1 1 3 4 1 4 1 1 4 1 4 1 7 4 1 5 1 2 3 1 1 1\n",
      " 1 1 4 1 1 1 1 1 7 4 1 1 7 1 7 1 1 2 4 4 2 1 4 5 4 4 4 1 4 1 2 1 1 1 1 1 1\n",
      " 1 1 1 4 1 1 1 1 1 1 1 7 1 2 1 1 4 1 4 4 1 1 1 1 1 4 1 1 0 1 1 4 1 1 0 1 1\n",
      " 5 4 5 1 1 1 4 1 1 4 2 1 0 1 1 1 1 1 2 1 2 1 1 4 1 1 1 4 3 1 4 7 4 1 4 4 1\n",
      " 1 1 4 1 1 4 1 1 1 7 6 1 1 1 1 1 4 7 1 7 7 4 4 5 1 1 1 7 4 4 1 5 7 1 4 5 1\n",
      " 1 2 1 1 0 3 1 1 5 4 1 1 1 1 1 7 1 1 1 4 0 4 4 1 4 7 1 7 1 1 2 4 5 5 4 1 1\n",
      " 3 1 1 1 0 1 1 2 1 1 4]\n"
     ]
    }
   ],
   "source": [
    "df_test['FareGroup'] = pd.cut(df_test['Fare'], bins=bins, labels=labels, right=False)\n",
    "print(df_test[['Fare','FareGroup']])\n",
    "\n",
    "del values\n",
    "print (df_test['FareGroup'].unique())\n",
    "values = array(df_test['FareGroup'])\n",
    "print(values)\n",
    "onehot_encoded = hot_encode_PC(values)\n",
    "\n",
    "\n",
    "# ha codificat aixi: 100-0, 20-1, 200-2, 300-3,  40-4, 60-5, 600-6, 80-7\n",
    "df_test['Fare20']=onehot_encoded[:,0]\n",
    "df_test['Fare40']=onehot_encoded[:,1]\n",
    "df_test['Fare60']=onehot_encoded[:,2]\n",
    "df_test['Fare80']=onehot_encoded[:,3]\n",
    "df_test['Fare100']=onehot_encoded[:,4]\n",
    "df_test['Fare200']=onehot_encoded[:,5]\n",
    "df_test['Fare300']=onehot_encoded[:,6]\n",
    "df_test['Fare600']=onehot_encoded[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked Deck  Number  Deck_A  \\\n",
      "0  34.5      0      0   330911   7.8292   NaN        Q    X     NaN     0.0   \n",
      "1  47.0      1      0   363272   7.0000   NaN        S    X     NaN     0.0   \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q    X     NaN     0.0   \n",
      "3  27.0      0      0   315154   8.6625   NaN        S    X     NaN     0.0   \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S    X     NaN     0.0   \n",
      "\n",
      "   Deck_B  Deck_C  Deck_D  Deck_E  Deck_F  Deck_G  Deck_X AgeGroup  adult  \\\n",
      "0     0.0     0.0     0.0     0.0     0.0     0.0     1.0    adult    1.0   \n",
      "1     0.0     0.0     0.0     0.0     0.0     0.0     1.0    adult    1.0   \n",
      "2     0.0     0.0     0.0     0.0     0.0     0.0     1.0     vell    0.0   \n",
      "3     0.0     0.0     0.0     0.0     0.0     0.0     1.0    adult    1.0   \n",
      "4     0.0     0.0     0.0     0.0     0.0     0.0     1.0    adult    1.0   \n",
      "\n",
      "    ...     SibSp0  SibSp1  SibSp2  SibSp3  SibSp4  SibSp5  SibSp8  Parch0  \\\n",
      "0   ...        1.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
      "1   ...        0.0     1.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
      "2   ...        1.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
      "3   ...        1.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
      "4   ...        0.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   Parch1  Parch2  Parch3  Parch4  Parch5  Parch6  FareGroup  Fare20  Fare40  \\\n",
      "0     0.0     0.0     0.0     0.0     0.0     0.0         20     0.0     1.0   \n",
      "1     0.0     0.0     0.0     0.0     0.0     0.0         20     0.0     1.0   \n",
      "2     0.0     0.0     0.0     0.0     0.0     0.0         20     0.0     1.0   \n",
      "3     0.0     0.0     0.0     0.0     0.0     0.0         20     0.0     1.0   \n",
      "4     1.0     0.0     0.0     0.0     0.0     0.0         20     0.0     1.0   \n",
      "\n",
      "   Fare60  Fare80  Fare100  Fare200  Fare300  Fare600  \n",
      "0     0.0     0.0      0.0      0.0      0.0      0.0  \n",
      "1     0.0     0.0      0.0      0.0      0.0      0.0  \n",
      "2     0.0     0.0      0.0      0.0      0.0      0.0  \n",
      "3     0.0     0.0      0.0      0.0      0.0      0.0  \n",
      "4     0.0     0.0      0.0      0.0      0.0      0.0  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# el dataframe amb el que aplicarem el model: df_Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ara ens quedem amb un dataframe amb nomes aquells labels que ens interssen pel model\n",
    "# Submission 0\n",
    "df_Titanic = df_train[['Survived','adult','bebe','infant','jove','nen','vell','female','male','Pclass1','Pclass2',\n",
    "                       'Pclass3','Deck_A','Deck_B','Deck_C','Deck_D','Deck_E','Deck_F','Deck_G','Deck_X',\n",
    "                       'SibSp0','SibSp1','SibSp2','SibSp3','SibSp4','SibSp5','SibSp8',\n",
    "                       'Parch0','Parch1','Parch2','Parch3','Parch4','Parch5','Parch6',\n",
    "                       'Fare20','Fare40','Fare60','Fare80','Fare100','Fare200','Fare300','Fare600']]\n",
    "\n",
    "df_Titanic_test = df_test[['adult','bebe','infant','jove','nen','vell','female','male','Pclass1','Pclass2',\n",
    "                       'Pclass3','Deck_A','Deck_B','Deck_C','Deck_D','Deck_E','Deck_F','Deck_G','Deck_X',\n",
    "                       'SibSp0','SibSp1','SibSp2','SibSp3','SibSp4','SibSp5','SibSp8',\n",
    "                       'Parch0','Parch1','Parch2','Parch3','Parch4','Parch5','Parch6',\n",
    "                       'Fare20','Fare40','Fare60','Fare80','Fare100','Fare200','Fare300','Fare600']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission 1\n",
    "\n",
    "df_Titanic = df_train[['Survived','adult','bebe','infant','jove','nen','vell','female','male','Pclass1','Pclass2',\n",
    "                       'Pclass3','Deck_A','Deck_B','Deck_C','Deck_D','Deck_E','Deck_F','Deck_G','Deck_X',\n",
    "                       'SibSp0','SibSp1','SibSp2','SibSp3','SibSp4','SibSp5','SibSp8',\n",
    "                       'Fare20','Fare40','Fare60','Fare80','Fare100','Fare200','Fare300','Fare600']]\n",
    "\n",
    "df_Titanic_test = df_test[['adult','bebe','infant','jove','nen','vell','female','male','Pclass1','Pclass2',\n",
    "                       'Pclass3','Deck_A','Deck_B','Deck_C','Deck_D','Deck_E','Deck_F','Deck_G','Deck_X',\n",
    "                       'SibSp0','SibSp1','SibSp2','SibSp3','SibSp4','SibSp5','SibSp8',\n",
    "                       'Fare20','Fare40','Fare60','Fare80','Fare100','Fare200','Fare300','Fare600']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 2\n",
    "\n",
    "df_Titanic = df_train[['Survived','adult','bebe','infant','jove','nen','vell','female','male','Pclass1','Pclass2',\n",
    "                       'Pclass3','Deck_A','Deck_B','Deck_C','Deck_D','Deck_E','Deck_F','Deck_G','Deck_X',\n",
    "                       'SibSp0','SibSp1','SibSp2','SibSp3','SibSp4','SibSp5','SibSp8']]\n",
    "\n",
    "df_Titanic_test = df_test[['adult','bebe','infant','jove','nen','vell','female','male','Pclass1','Pclass2',\n",
    "                       'Pclass3','Deck_A','Deck_B','Deck_C','Deck_D','Deck_E','Deck_F','Deck_G','Deck_X',\n",
    "                       'SibSp0','SibSp1','SibSp2','SibSp3','SibSp4','SibSp5','SibSp8']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 3\n",
    "\n",
    "df_Titanic = df_train[['Survived','adult','bebe','infant','jove','nen','vell','female','male','Pclass1','Pclass2',\n",
    "                       'Pclass3','Deck_A','Deck_B','Deck_C','Deck_D','Deck_E','Deck_F','Deck_G','Deck_X']]\n",
    "\n",
    "df_Titanic_test = df_test[['adult','bebe','infant','jove','nen','vell','female','male','Pclass1','Pclass2',\n",
    "                       'Pclass3','Deck_A','Deck_B','Deck_C','Deck_D','Deck_E','Deck_F','Deck_G','Deck_X']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 42)\n",
      "Survived    1.000000\n",
      "adult      -0.073645\n",
      "bebe        0.122966\n",
      "infant      0.077441\n",
      "jove       -0.008758\n",
      "nen         0.044716\n",
      "vell       -0.040857\n",
      "female      0.543351\n",
      "male       -0.543351\n",
      "Pclass1     0.285904\n",
      "Pclass2     0.093349\n",
      "Pclass3    -0.322308\n",
      "Deck_A      0.022287\n",
      "Deck_B      0.175095\n",
      "Deck_C      0.114652\n",
      "Deck_D      0.150716\n",
      "Deck_E      0.145321\n",
      "Deck_F      0.057935\n",
      "Deck_G      0.016040\n",
      "Deck_X     -0.316912\n",
      "SibSp0     -0.115867\n",
      "SibSp1      0.173076\n",
      "SibSp2      0.029796\n",
      "SibSp3     -0.037215\n",
      "SibSp4     -0.064123\n",
      "SibSp5     -0.059292\n",
      "SibSp8     -0.070234\n",
      "Parch0     -0.147408\n",
      "Parch1      0.134174\n",
      "Parch2      0.075020\n",
      "Parch3      0.033391\n",
      "Parch4     -0.053002\n",
      "Parch5     -0.028398\n",
      "Parch6     -0.026456\n",
      "Fare20      0.162583\n",
      "Fare40     -0.255496\n",
      "Fare60      0.150716\n",
      "Fare80      0.075486\n",
      "Fare100     0.051066\n",
      "Fare200     0.099358\n",
      "Fare300     0.073642\n",
      "Fare600     0.055730\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_Titanic.shape)\n",
    "\n",
    "cor=df_Titanic.corr()\n",
    "print(cor.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer test de model --> Sembla que el millor era LogisticRegression\n",
    "\n",
    "exemple: https://www.kaggle.com/gautham11/building-a-scikit-learn-classification-pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with all the available data\n",
    "1. hem algunes proves i sembla que els millors resultats, per ara son sense considerar els Parch ni fare\n",
    "2. Ara provare amb tot menys Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic_array = array(df_Titanic)\n",
    "X_train= Titanic_array[:,1:] # ho te tot.\n",
    "Y_train= Titanic_array[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 41)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1) Train the model: els parametres els hem aconseguit fent un gridsearch\n",
    "\n",
    "clf = LogisticRegression(C=0.6894736842105262, class_weight=None, dual=True,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=200,\n",
    "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# 2 Predict the data\n",
    "X_test = array(df_Titanic_test)\n",
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# no hem optimitzat parametres\n",
    "\n",
    "clf = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
    "              max_features=None, max_leaf_nodes=None,\n",
    "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# 2 Predict the data\n",
    "X_test = array(df_Titanic_test)\n",
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, LinearSVR, SVC\n",
    "\n",
    "clf=LinearSVC(C=1, dual=False, fit_intercept=True, intercept_scaling=10,penalty='l2')\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# 2 Predict the data\n",
    "X_test = array(df_Titanic_test)\n",
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=1000)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# 2 Predict the data\n",
    "X_test = array(df_Titanic_test)\n",
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         0\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({'PassengerId':df_test['PassengerId'],'Survived':prediction})\n",
    "submission.head()\n",
    "#df.a = df.a.astype(float)\n",
    "submission['Survived'] = submission['Survived'].astype(int)\n",
    "print (submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: Titanic_Predictions_RandomForestC0.csv\n"
     ]
    }
   ],
   "source": [
    "#Convert DataFrame to a csv file that can be uploaded\n",
    "#This is saved in the same directory as your notebook\n",
    "filename = 'Titanic_Predictions_RandomForestC0.csv'\n",
    "\n",
    "submission.to_csv(filename,index=False)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amb aquest primera hem tret un 0.76"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
